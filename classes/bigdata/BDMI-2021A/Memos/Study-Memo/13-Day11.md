# 第十一堂学习小结

> **陈彦扬 2019080117 软件93**

## 自动微分

### 求导运算

#### 数值微分

- 根据导数定义来微分

#### 符号微分

- 求导结果的表达式

#### 自动微分

##### 前向模式

- 计算输出对某个输入的微分

![](https://gitee.com/YYTan/image/raw/master/%E7%AC%AC%E4%B8%83%E6%AC%A1%E5%B0%8F%E7%BB%93/%E8%87%AA%E5%8A%A8%E5%BE%AE%E5%88%86%E7%9A%84%E5%89%8D%E5%90%91%E6%A8%A1%E5%BC%8F.png)

##### 反向模式

- 计算输出对所有输入的微分值

![](https://gitee.com/YYTan/image/raw/master/%E7%AC%AC%E4%B8%83%E6%AC%A1%E5%B0%8F%E7%BB%93/%E8%87%AA%E5%8A%A8%E5%BE%AE%E5%88%86%E5%8F%8D%E5%90%91%E6%A8%A1%E5%BC%8F.png)



#### 传播与自动微分

- 反向传播是在神经网络上执行梯度下降法的主要算法。 
- 反向传播算法
  - 先按前向传播方式计算每个节点的输出值
  - 然后再按反向传播遍历图的方式
  - 计算损失函数值相对于每个参数的偏导数

## 多层人工神经网络

- 单个神经元可以进行线性分类，而多个神经元的组合就可以完成复杂 的分类工作，比如解决异或（XOR）问题。 

- 多层神经网络，又称为深度神经网络，在实际中表现出更好的性能。 



## 多层人工神经网络的层间连接关系

- 前馈网络

- 反馈网络

- 记忆网络

![](https://gitee.com/YYTan/image/raw/master/%E7%AC%AC%E4%B8%83%E6%AC%A1%E5%B0%8F%E7%BB%93/%E7%BD%91%E7%BB%9C%E6%8B%93%E6%89%91%E7%BB%93%E6%9E%84.png)

#### 全连接

- 又称为密集连接（Dense) 

- 输入特征与中间（每个）神经元进行边连接 

- 隐藏层和下一个隐藏层的神经元全连接 

![](https://gitee.com/YYTan/image/raw/master/%E7%AC%AC%E4%B8%83%E6%AC%A1%E5%B0%8F%E7%BB%93/%E5%85%A8%E8%BF%9E%E6%8E%A5%E4%BE%8B%E5%AD%90.png)

### 卷积核与卷积运算

##### 卷积核（kernel/Filter)是一个多维数组

- 参数由学习算法得到的

- 卷积核数目一般选32、 64等

##### 卷积是对输入的多维数组的数据，应用卷积核的过程

- 输入一般是图片，可以用张量表示(Tensor)

##### 卷积（Convolution）是一种张量运算

![](https://gitee.com/YYTan/image/raw/master/%E7%AC%AC%E4%B8%83%E6%AC%A1%E5%B0%8F%E7%BB%93/%E5%8D%B7%E7%A7%AF%E6%A0%B8%E4%B8%8E%E5%8D%B7%E7%A7%AF%E8%BF%90%E7%AE%97.png)



### 2D卷积核

卷积核是一个多维数组，其中参数由学习算法得到的 

输出长度计算： 

- 填充式（P, padding)，填零（zero-padding)

- 输入的长度（W)

- 卷积核（filter）的大小（F)

- 卷积核移动的步长（S, stride)

- 输出的长度L=(W - F+2P)/S+1



### 下采样层 

每一个卷积层后通常紧跟着一个下采样层 (subsample/down sampling) 

下采样的作用是缩小输出张量的大小 

下采样方法： 

- 最大池化（max- pooling方法），取其中最大值 

- 平均池化（avg - pooling方法），取其中的平均值 



## 网络结构

#### 人工神经元 

单个人工神经元（Artificia Neuron) :

- 一组输入的线性加权叠加

- 经过一个非线I陛变换进行输出



# Keras

Keras是一套高级API（应用程序接口），用来快速搭建深度神经网络

tensorflow.keras是基于TensorFlow2实现的快速搭建深度神经网络的程序库 



#### Keras优点

- 设计采用极简主义原则（Minimalist)，是一套高度模块化的人工神经网络架构库。 

- 具有方便易用的特点，如简洁的网络定义方式，常用技巧的封装。

- 保留了足够的扩展性，同时具有灵活性，可以自行实现各种层（layers)。 

- 用户众多，适合快速学习、快速搭建深度学习网络 。

```python
import tensorflow as tf
from tensorflow import keras
```



#### Keras核心概念一模型 

Keras核心的数据结构叫模型（Model) 

模型是组织层的一种方式，包括架构（连接关系）和权重参数。 

最简单的Model类型是顺序模型（Sequential model)。 

- 顺序模型是指串接很多层的线形管道（a linear pile of layers)。



#### Keras核心概念一顺序模型 

> 顺序模型（Sequential model)，又称为序列模型 
>
> 网络结构是以一个栈的形式给出，一层接一层。 

```python
# Define Sequential model with 3 layers 
model = keras.Sequential( 
	[ 
		layers.Dense(2, activation="relu", name="layer1"), 
		layers.Dense(3, activation="relu", name="layer2"), 
		layers.Dense(4, name="layer3"), 
	]
)

#Call model on a test input
x = tf.ones((3,3))
y = model(x)

#Create 3 layers
layerl = layers.Dense(2, activation="relu", name="layerl") 
layer2 = layers.Dense(3, activation="relu", name="layer2") 
layer3 = layers.Dense(4, name="layer3") 

# Call layers on a test input 
x = tf.ones((3, 3)) 
y = layer3(layer2(layerl (x))) 
```

#### Keras核心概念-层-1 

> Module	:	 tf.keras.Iayers 

#### Keras核心概念-层-2 

> Module	:	 tf.keras.layers 

#### Keras核心概念-激活函数 

> Module	:	 tf.keras.activations 

#### Keras核心概念一优化器1 

#### Keras核心概念-优化器2 



## Keras 的使用流程

#### 1、定义网络

示例，基于顺序模型 

- 网络结构是以一个栈的形式给出，一层接一层。 

代码解读： 

- 第一层的input_shape/input_dim参数指定了输入层的大小。 

  - Input_dim是第一层的参数列表，而与第一层是什么类型的网络无关。

  - 这里指定一个784维的输入。

最后一层一般是softmax作为输出层。 

- 给出了10个输出表示该网络解决10类分类的问题。 

```python
from keras.models import Sequential 
from keras.layers import Dense, Activation 

model = Sequential([ 
    Dense(32, input_dim=784), 
    Activation('relu'), 
    Dense(10),
    Activation('softmax'),
]) 
```

#### 2、编译网络 

编译、编排网络 

- 给定网络的训练目标 

-  给定网络的优化算法 

代码解读 

- 'loss'：是指网络使用多类交叉嫡作为优化目标。 

- 'optimizer': 是指使用RMSprop算法进行梯度下降。 

- 'metrics': 是指在训练过程中，希望观察到准确度这个指标是如何变化的。 

```python 
model.compile(optimizer='rmsprop', 
loss='categorical_crossentropy',metrics=['accuracy']) 
```

#### 3、网络训练 

代码解读： 

- 产生1000个符合input_shape的数据，以及标签，然后传给model.fit(), 从而开始迭代训练过程。 

训练过程会动态输loss accuracy等参数。 

```python
import numpy as np 
data=np.random.random((1000,784)) 
labels=np.random.randint(2,size=(1000,1)) 
#train the model,iterating on the data in batches of 32 samples 
model.fit(data, labels,nb_epoch=10,batch_size=32) 
```

#### 4、评估网络 

评估网络（Evaluate)：检查训练效果 

方法：modeI.evaluate() 

```python
model.evaluate(self, x,y, batch_size=32,verbose=1, sample_weight=None) 
```

#### 5、数据预测（Predict) 

数据预测（Predict) 

方法：model.predict() 

```python
model.predict(self, x,batch_size=32,verbose=0) 
```

#### 6、保存／载入网络 

将保存／载入网络结构与参数

方法： 

- model.save(）或tf.keras.models.save_model() 

- tf.keras.models.load_model() 

不推荐：采用hdf5格式保存网络参数数据。

```python
from keras.models import load_model 
model.save('./model.h5') 
model2=load_ model('./model.h5') 
```