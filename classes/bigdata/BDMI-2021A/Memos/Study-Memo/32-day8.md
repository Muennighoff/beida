## 学习小结-1103-day8
---

#### 1. Python pandas

- 进行数据处理的一个库，有三种基本结构

  - 一维数据`Series`

    可以存储任意类型数据，索引叫做`index`，调用方法为

    ```python
    s = pd.Series(data, index=index)
    ```

    `data`可以是字典、`ndarray`、标量等，`index`是一维坐标轴的索引列表

  - 二维数据`DataFrame`

    从`Series`字典中构造

    ```python
    d = {'one' : pd.Series([1.,2.,3.],index=['a','b','c']),
         'two' : pd.Series([1.,2.,3.,4.],index=['a','b','c','d'])}
    df = pd.DataFrame(d)
    ```

  - 三维数据`Panel`

#### 2. 多层神经网络

- 自动化的权重确定的过程，也称为神经网络的训练，或称为网络权重的学习过程

- 一般流程：

  - 确定损失函数（Loss）：定义损失函数

    引入度量函数：度量`y`与`y'`的差异，计算出差异值`Delta`，比如绝对值求和、平均绝对值求和、平方和误差、均方差（Mean Squared Error，MSE）、交叉熵（Cross Entropy）等

    对于回归任务，通过MSE的公式来计算损失

    对于分类任务，通过CE的公式来计算损失

    交叉熵是**负对数似然损失函数**，交叉熵损失函数表示如下
    $$
    H_{y'}(y)=-\Sigma_i y'_i log(y_i)
    $$
    `y'`表示训练样本对应的标签，`y`表示神经网络的输出

  - 权重初始化（Initialization）：随机初始化

  - 反向传播（Back Propagation）：计算损失函数对权重的梯度

    损失函数是权重值的函数

    最优化算法：梯度下降法，也称为最速下降法

    反向传播算法

    正则化：有助于防止出现过拟合，包含L1正则化、L2正则化、丢弃正则化

  - 权重修正（Weights Adjusting）：随机梯度下降法

    随机梯度下降方法（Stochastic Gradient Descent，SGD）是最常用的权重调节方法，可通过权重调整，最小化损失函数

    步骤：1、随机初始化每个神经元输入权重和偏差；2、选取一个随机样本；3、根据网络的输出结果，从最后一层开始后，逐层计算每层权重的偏导数；4、逐层调整每层的权重，产生新的权重值；返回步骤2，继续随机选取下一个样本

- 神经网络运用的一般流程

  - 准备数据集

  - 搭建网络模型

  - 训练模型

  - 测试模型

    模型是秩多层神经网络的结构（Architecture）和相应的每层的权重数值（Weights）

#### 3. 逻辑斯提回归实践（Logistic Regression）

- 二元分类演示实验
  - 根据个体的身体体征，猜测性别
  - 数据集：取40人的数据，输入每个个体的身体特征
  - 效果：给出一个体的身体体征，得出是女生的可能性
- 自动化训练流程
  - 获取训练数据
  - 搭建模型
  - 定义损失函数
  - 运行训练数据，从目标值计算损失
  - 计算损失的梯度，并使用优化器来调整变量以适应数据
  - 结果评估
