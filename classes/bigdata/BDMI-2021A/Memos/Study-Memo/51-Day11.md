# 第11课总结

#### 自动微分

数值微分 符号微分 自动微分

前向模式：计算输出对某个输入的微分

 反向模式：计算输出对所有输入的微分

#### 卷积网络

卷积核与卷积运算：等大做乘法

输出长度：（P:padding，W：输入长度，F卷积核大小，卷积核移动步长S)

输出长度L=（W-F+2P）/S+1

下采样层：最大池化/平均池化

正则化层：在最大池化层后：eg:LCN,减去平均，除以标准差

#### Keras

顺序模型：Sequential model

核心概念：Dence Activation Dropout Flatten Reshape

激活函数：softmax elu softplus softsign relu tanh sigmoid hard_sigmoid linear

优化器：Optimizer基类 SGD梯度下降 RMSprop Adagrad Adadelta Adam Adamax Nadam

 RMSprop Adagrad  Adam:带有自适应调整学习率

 Adagrad：计算每个维度的学习率

使用流程：

1. 定义
2. 编译
3. 训练
4. 评估
5. 数据预测
6. 保存/载入网络 

add_weights 添加权重

get_weights set_weights(layer_2.set_weights(layer_1.get_weights))权重转移

model.save_weights权重保存 load_weights权重加载

