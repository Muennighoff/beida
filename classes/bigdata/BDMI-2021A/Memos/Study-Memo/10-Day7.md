# Week 7 Summary

# 课程大纲
```
Python Numpy（深度学习基础）
Deep learning：人工神经元
Python Pandas
Deep learning：多层网络
TensorFlow PlayGround体验
```

## Numpy
````
章节内容
	简介
	数组创建于类型定义
	算术运算
	矩阵运算
	数组形状变形
	debugging


pip install numpy
pip install scipy

scipy实际上是基于numpy的

使用numpy.array()来创建数组
	其内容可以是list(s)，tuple(s)
	它可以包含数字以外的内容（str）
数组运算无特别
	a+4
	a*3
	a+b
如果是单个数字，它会对其内的数字做相同处理
如果是数组相加减乘除，他会对对应位置元素进行相应操作
它也可以是其他运算方式
	a * np.sin(b)
	a * np.sqrt(b)

创建数组的时候可以设定矩阵规格
	A = np.arange(0, 9) (1x9)
	A = np.arange(0, 9).reshape(3, 3) (3x3)

创建的时候也可以建立全部为1的矩阵
	B = np.ones((3, 3))

代数相乘的时候使用如下指令：
	np.dot(A, B)
	貌似 A@B 也是可行的
	其结果是A行与B列的对应位置的数字相乘，结果相加，左上就是A1行xB1列，中上就是A1行xB2列。。。
	
通过 += 、 -= 、 *= 、 /= 来更新保存新数组

np.random.random(12).reshape(3,4)
创建3x4的由12个0-1的随机数组成

其他方法：
np.matmul 矩阵相乘
np.zeros (与ones相同)
np.arange (start,stop,setp size)
np.identity 创建一个单位矩阵
np.vstack 垂直叠加2阵列
np.hstack 水平叠加2阵列

调试方法：
array.shape
array.dtype 检查给定数据类型
type()
import pdb; pdb.set_trace() 设置断点 (python 模块调试常用库)
print(f'My name is {name}') 打印信息

```
pdb 代码示范：（总共有十来条命令）

import pdb
i=0
while i<20:
	pdb.set_trace()
	print('i=',i)
	i=i+1
```
````

## Deep Learning: 人工神经元
```
单个人工神经元

激活函数(activation function)
	sigmoid函数 1/(1+e^-x)
	tanh函数 (e^x - e^-x)/(e^x + e^-x)
	ReLU函数 max(x, 0)
	
ReLU单元(整流线性单元)
	y = max(0, -0.21 * x1 + 0.3 * x2 + 0.7 * x3)
	
布尔运算
	现代计算机的基础能力
	and or not nand xor
	
AND 与运算
	x1，x2选值为{0，1}
	w1，w2为20
	偏置b=-30
	（0，0）σ（-30）；（0，1）σ（-10）；（1，1）σ（10）
	在σ（sigma）模型中 小于-5为0，大于5为1

OR 或运算
	与AND相同，偏置改为-10
	
NOT 非运算
	只剩下1个x
	w 为 -20
	偏置为 10
	
NAND 与非门
	w1, w2 为-20
	偏置为30
	只有 (1,1)会得到0，其他都是1
	
特殊：
XOR 运算
	输入：X1,X2 {0,1}
	输出{0，1}
	相同的话给出0
	不同的时候给出1
	X1 XOR X2 = {X1 or x2} and {nand{x1,x2}}
	or
	x1 xor x2 = {x1 or x2} and { (not x1) or (not x2)}
	
```

## 深度学习2：多层神经网络
> 名词术语
> 随机梯度下降法（SGD， stochastic gradient descent）
> 。。。
> 
> 它是什么方法？
> 属于监督学习
> 
> 机器学习（ML）
> > 根据输入数据构建（训练）预测模型
> > 根据已有模型对型数据进行预测
> 机器学习的三种主要范式分别为：
> > 监督学习-1： 决策树、决策森林、支撑向量机。。。
> > 监督学习-2： 神经网络、全连接网络、循环网络。。。
> > 非监督学习：降维方法、聚类
> > 强化学习：策略梯度、深度Q网络。。。
> 
> 数据集：
> 训练集training set，训练模型
> 验证集validation set，从训练集分离，用于验证学习效果
> 测试集test set，数据集的子集，用于测试模型
> 
> 机器学习主要解决两类任务：
> > 分类任务，classification
> > 预测任务，regression
> 
> 监督式机器学习（supervised machine learning）
> > 根据训练集的样本进行学习，推断新的例子
> > 从有标签的样本中学习规律
> 
> model 模型 是机器学习系统从训练数据学到的内容的表示形式
> 有标签的样本是非常重要的（在训练的时候我们需要准备好有标签的数据集）
> 标签数据集中的每个样本都包含一个或多个特征以及一个标签
> 
> 迁移学习（transfer learning）
> > 将信息从一个机器学习任务迁移到另一个机器学习任务
> 
> 深度学习
>
> 单个神经元最常用于 二元分类
> 合适的权重一般使用 经验调参法
> 
> Softmax处理
> 计算概念分布向量
> 所有输出的数值是正的，所有分量之和为1
> g(zm) = e^zm / Σk e^zk
> def softmax(x):
> 	x = np.exp(x)
>	return x / np.sum(x)