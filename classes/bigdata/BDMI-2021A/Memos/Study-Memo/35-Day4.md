# 2-3-4 Tree

Generalize BST node to allow multiple keys. 

Keep tree in perfect balance. 



Perfect balance: Every path from root to leaf has same length. 



Allow 1, 2, or 3 keys per node. 

• 2-node: one key, two children. 

<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/b/b2/2-3-4-tree-2-node.svg/95px-2-3-4-tree-2-node.svg.png" alt="img"  />

• 3-node: two keys, three children. 

![img](https://upload.wikimedia.org/wikipedia/commons/thumb/1/13/2-3-4-tree-3-node.svg/120px-2-3-4-tree-3-node.svg.png)

• 4-node: three keys, four children.

![img](https://upload.wikimedia.org/wikipedia/commons/thumb/3/35/2-3-4-tree-4-node.svg/120px-2-3-4-tree-4-node.svg.png)



### Insertion:

##### To insert the value "25" into this 2–3–4 tree:

![2-3-4-tree-insertion-stage-1.svg](https://upload.wikimedia.org/wikipedia/commons/thumb/7/73/2-3-4-tree-insertion-stage-1.svg/308px-2-3-4-tree-insertion-stage-1.svg.png)

- Begin at the root (10, 20) and descend towards the rightmost child (22, 24, 29). (Its interval (20, ∞) contains 25.)
- Node (22, 24, 29) is a 4-node, so its middle element 24 is pushed up into the parent node.

![2-3-4-tree-insertion-stage-2.svg](https://upload.wikimedia.org/wikipedia/commons/thumb/b/b8/2-3-4-tree-insertion-stage-2.svg/274px-2-3-4-tree-insertion-stage-2.svg.png)

- The remaining 3-node (22, 29) is split into a pair of 2-nodes (22) and (29). Ascend back into the new parent (10, 20, 24).
- Descend towards the rightmost child (29). (Its interval (24, ∞) contains 25.)

![2-3-4-tree-insertion-stage-3.svg](https://upload.wikimedia.org/wikipedia/commons/thumb/c/c8/2-3-4-tree-insertion-stage-3.svg/300px-2-3-4-tree-insertion-stage-3.svg.png)

- Node (29) has no leftmost child. (The child for interval (24, 29) is empty.) Stop here and insert value 25 into this node.

![2-3-4-tree-insertion-stage-4.svg](https://upload.wikimedia.org/wikipedia/commons/thumb/8/8b/2-3-4-tree-insertion-stage-4.svg/349px-2-3-4-tree-insertion-stage-4.svg.png)



### Deletion:

Deleting an element in a 2-3-4 tree assumes we will *grow* (merge) nodes on the way down.

The idea is intuitive, but writing the algorithm down in English seems to make it look/sound harder than it is.

Again, when dealing with trees, there are different cases. Here, there are 3 different cases:

1. If the element, k is in the node and the node is a leaf containing at least 2 keys, simply remove k from the node.
2. If the element, k is in the node and the node is an internal node perform one of the following:
   1. If the element's *left* child has at least 2 keys, replace the element with its predecessor, *p*, and then recursively delete *p*.
   2. If the element's *right* child has at least 2 keys, replace the element with its successor, *s*, and then recursively delete *s*.
   3. If both children have only 1 key (the minimum), merge the right child into the left child and include the element, *k*, in the left child. Free the right child and recursively delete *k* from the left child.
3. If the element, k, is not in the internal node, follow the proper link to find k. To ensure that all nodes we travel through will have at least 2 keys, you may need to perform one of the following before descending into a node. Then, you will descend into the corresponding node. Eventually, case 1 or 2 will be arrived at (if k is in the tree).
   1. If the child node (the one being descending into) has only 1 key and has an immediate sibling with at least 2 keys, move an element down from the parent into the child and move an element from the sibling into the parent.
   2. If both the child node and its immediate siblings have only 1 key each, merge the child node with one of the siblings and move an element down from the parent into the merged node. This element will be the middle element in the node. Free the node whose elements were merged into the other node.

Also, much like when deleting from a binary tree, all deletions are actually done at the leaf level, meaning that Case #1 is the way all items are actually deleted from the tree. We may have to push elements down into the leaves before actually deleting them.

1. Given this tree:

2. ![img](https://azrael.digipen.edu/~mmead/www/Courses/CS280/Trees-234-delete-1.png)

3. We are going to delete the nodes in this order: A N H R C P E F V B X Y S Z. Deleting the nodes in this order will demonstrate each of the possible cases above.

4. 

5. Deleting **A** is Case #1: **A** is in a leaf and there are at least 2 keys in the node.

6. ![img](https://azrael.digipen.edu/~mmead/www/Courses/CS280/Trees-234-delete-2.png)

7. 

8. This is the simplest case: Just remove **A** from the node, resulting in this tree:

9. ![img](https://azrael.digipen.edu/~mmead/www/Courses/CS280/Trees-234-delete-3.png)

10. 

11. 

12. ------

13. 

14. Deleting **N** is Case #3.1: **N** is in a leaf node, and it is the only key in the node.

15. ![img](https://azrael.digipen.edu/~mmead/www/Courses/CS280/Trees-234-delete-4.png)

16. 

17. There are at least 2 keys in the sibling node, so move the right-most key to the parent, and move the right-most parent down.

    ![img](https://azrael.digipen.edu/~mmead/www/Courses/CS280/Trees-234-delete-5.png)

    

18. Now There are 2 keys in the leaf node, which is case #1. Just delete **N**, resulting in this tree:

19. ![img](https://azrael.digipen.edu/~mmead/www/Courses/CS280/Trees-234-delete-6.png)

20. 

21. 

22. ------

23. 

24. Deleting **H** is case #3.2: **H** is in a leaf node, and there are no siblings with at least 2 keys.

25. ![img](https://azrael.digipen.edu/~mmead/www/Courses/CS280/Trees-234-delete-7.png)

26. 

27. The parent has at least 2 keys, so we merge the right-most parent with its children:

28. ![img](https://azrael.digipen.edu/~mmead/www/Courses/CS280/Trees-234-delete-8.png)

29. 

30. Now we can simple delete **H** from the leaf node, resulting in this tree:

31. ![img](https://azrael.digipen.edu/~mmead/www/Courses/CS280/Trees-234-delete-9.png)

32. 

33. 

34. ------

35. 

36. Deleting ***any\*** key from a leaf node will first require that we merge the root, **P** with its two children (**C** and **V**) because of the "merge on the way down" rule.

37. ![img](https://azrael.digipen.edu/~mmead/www/Courses/CS280/Trees-234-delete-10.png)

38. 

39. After merging the root with its children:

40. ![img](https://azrael.digipen.edu/~mmead/www/Courses/CS280/Trees-234-delete-11.png)

41. 

42. 

43. ------

44. 

45. Now we can proceed to delete **R**, which is case #1, **R** is in a leaf node and there are at least 2 keys in the node:

46. ![img](https://azrael.digipen.edu/~mmead/www/Courses/CS280/Trees-234-delete-12.png)

47. 

48. After deleting **R**, the resulting tree looks like this:

49. ![img](https://azrael.digipen.edu/~mmead/www/Courses/CS280/Trees-234-delete-13.png)

50. 

51. 

52. ------

53. 

54. Deleting **C** is case #2.2: **C** is in an internal node, and its right child has at least two keys:

55. ![img](https://azrael.digipen.edu/~mmead/www/Courses/CS280/Trees-234-delete-14.png)

56. 

57. We replace **C** with its *successor*, which is **E**:

58. ![img](https://azrael.digipen.edu/~mmead/www/Courses/CS280/Trees-234-delete-15.png)

59. 

60. Now we continue the search looking for **E**. Since **E** is in a leaf node and there are at least 2 keys in the node, we just delete **E**, resulting in this tree:

61. ![img](https://azrael.digipen.edu/~mmead/www/Courses/CS280/Trees-234-delete-16.png)

62. 

63. 

64. ------

65. 

66. Deleting **P** is case #2.3. **P** is in an internal node, and both of its children only have a single key:

67. ![img](https://azrael.digipen.edu/~mmead/www/Courses/CS280/Trees-234-delete-17.png)

68. 

69. So we merge P with its children. Now P is in a leaf node which has at least 2 keys:

    ![img](https://azrael.digipen.edu/~mmead/www/Courses/CS280/Trees-234-delete-18.png)

    

70. Now we can simply delete **P**, yeilding this tree:

71. ![img](https://azrael.digipen.edu/~mmead/www/Courses/CS280/Trees-234-delete-19.png)

72. 

73. 

74. ------

75. 

76. Deleting **E** is case #2.2: **E** is in an internal node and its right childe has at least 2 keys, so we replace **E** with its successor, **F**.

77. ![img](https://azrael.digipen.edu/~mmead/www/Courses/CS280/Trees-234-delete-20.png)

78. 

79. Now we can delete the original **F** because it is in a leaf node that contains at least 2 keys, resulting in this tree:

80. ![img](https://azrael.digipen.edu/~mmead/www/Courses/CS280/Trees-234-delete-21.png)

81. 

82. 

83. ------

84. 

85. Deleting **F** is case #2.3. **F** is in an internal node, and both of its children only have one key:

86. ![img](https://azrael.digipen.edu/~mmead/www/Courses/CS280/Trees-234-delete-22.png)

87. 

88. So we merge **F** with its children, giving us this tree:

89. ![img](https://azrael.digipen.edu/~mmead/www/Courses/CS280/Trees-234-delete-23.png)

90. 

91. Now, **F** is in a leaf node that has at least 2 keys, so we simply delete **F**:

92. ![img](https://azrael.digipen.edu/~mmead/www/Courses/CS280/Trees-234-delete-24.png)

93. 

94. 

95. ------

96. 

97. Deleting **V** is case #2.1. **V** is in an internal node, and its left child has at least 2 keys:

98. ![img](https://azrael.digipen.edu/~mmead/www/Courses/CS280/Trees-234-delete-25.png)

99. 

100. So, we replace **V** with its *predecessor*, which is **S**:

101. ![img](https://azrael.digipen.edu/~mmead/www/Courses/CS280/Trees-234-delete-26.png)

102. 

103. Now we delete the original **S** because it is in a leaf node that has at least 2 keys, resulting in this tree:

104. ![img](https://azrael.digipen.edu/~mmead/www/Courses/CS280/Trees-234-delete-27.png)

105. 

106. 

107. ------

108. 

109. Deleting **B** is case #3.1. **B** is in a leaf that has only 1 key, but its sibling has at least 2 keys:

110. ![img](https://azrael.digipen.edu/~mmead/www/Courses/CS280/Trees-234-delete-28.png)

111. 

112. So we replace the parent key, **S**, with **S**'s successor, **X**, and move **S** into its left child, giving us this tree:

113. ![img](https://azrael.digipen.edu/~mmead/www/Courses/CS280/Trees-234-delete-29.png)

114. 

115. Now, the node with **B** has at least 2 keys and is a leaf node, so we can simply delete **B** resulting in this tree:

116. ![img](https://azrael.digipen.edu/~mmead/www/Courses/CS280/Trees-234-delete-30.png)

117. 

118. 

119. ------

120. 

121. Deleting **X** is case #2.2, **X** is in an internal node, and there is at least 2 keys in its right child:

122. ![img](https://azrael.digipen.edu/~mmead/www/Courses/CS280/Trees-234-delete-31.png)

123. 

124. So we replace **X** with it's successor, **Y**:

125. ![img](https://azrael.digipen.edu/~mmead/www/Courses/CS280/Trees-234-delete-32.png)

126. 

127. Now we can delete the original **Y** because it is in a leaf that has at least 2 keys, giving us this tree:

128. ![img](https://azrael.digipen.edu/~mmead/www/Courses/CS280/Trees-234-delete-33.png)

129. 

130. 

131. ------

132. 

133. Deleting **Y** is case #2.3. **Y** is in an internal node and both of its children have only 1 key:

134. ![img](https://azrael.digipen.edu/~mmead/www/Courses/CS280/Trees-234-delete-34.png)

135. 

136. Merging **Y** (the root) with its children gives us this tree:

137. ![img](https://azrael.digipen.edu/~mmead/www/Courses/CS280/Trees-234-delete-35.png)

138. 

139. Now, deleting **Y** (which is case #1) yields this tree:

140. ![img](https://azrael.digipen.edu/~mmead/www/Courses/CS280/Trees-234-delete-36.png)

141. 

142. 

143. ------

144. 

145. Since we have only one node, which is a leaf, deleting **S** is case #1, and gives us this tree:

146. ![img](https://azrael.digipen.edu/~mmead/www/Courses/CS280/Trees-234-delete-37.png)

147. 

148. 

149. ------

150. 

151. Finally, deleting **Z** is also case #1 and yields an empty tree.



# Left Leaning Red Black Tree

![img](https://user-images.githubusercontent.com/42311992/55536739-1c16b980-56ed-11e9-8fec-517d730f8633.png)

# B+ Tree

A B+ tree is an advanced form of a self-balancing tree in which all the values are present in the leaf level.

An important concept to be understood before learning B+ tree is multilevel indexing. In multilevel indexing, the index of indices is created as in figure below. It makes accessing the data easier and faster.

#### Properties of a B+ Tree

1. All leaves are at the same level.
2. The root has at least two children.
3. Each node except root can have a maximum of m children and at least m/2 children.
4. Each node can contain a maximum of m - 1 keys and a minimum of ⌈m/2⌉ - 1 keys.



The following steps are followed to search for data in a B+ Tree of order m. Let the data to be searched be k.

1. Start from the root node. Compare k with the keys at the root node [k1, k2, k3,......km - 1].
2. If k < k1, go to the left child of the root node.
3. Else if k == k1, compare k2. If `k < k``2`, k lies between k1 and k2. So, search in the left child of k2.
4. If k > k2, go for k3, k4,...km-1 as in steps 2 and 3.
5. Repeat the above steps until a leaf node is reached.
6. If k exists in the leaf node, return true else return false.



![b--search](https://iq.opengenus.org/content/images/2018/06/b--search.jpg)

### Algorithm



- **Basic operations associated with B+ Tree:**

- - **Searching a node in a B+ Tree**
    - Perform a binary search on the records in the current node.
    - If a record with the search key is found, then return that record.
    - If the current node is a leaf node and the key is not found, then report an unsuccessful search.
    - Otherwise, follow the proper branch and repeat the process.
  - **Insertion of node in a B+ Tree:**
    - Allocate new leaf and move half the buckets elements to the new bucket.
    - Insert the new leaf's smallest key and address into the parent.
    - If the parent is full, split it too.
    - Add the middle key to the parent node.
    - Repeat until a parent is found that need not split.
    - If the root splits, create a new root which has one key and two pointers. (That is, the value that gets pushed to the new root gets removed from the original node)
  - **Deletion of a node in a B+ Tree:**
    - Descend to the leaf where the key exists.
    - Remove the required key and associated reference from the node.
    - If the node still has enough keys and references to satisfy the invariants, stop.
    - If the node has too few keys to satisfy the invariants, but its next oldest or next youngest sibling at the same level has more than necessary, distribute the keys between this node and the neighbor. Repair the keys in the level above to represent that these nodes now have a different “split point” between them; this involves simply changing a key in the levels above, without deletion or insertion.
    - If the node has too few keys to satisfy the invariant, and the next oldest or next youngest sibling is at the minimum for the invariant, then merge the node with its sibling; if the node is a non-leaf, we will need to incorporate the “split key” from the parent into our merging.
    - In either case, we will need to repeat the removal algorithm on the parent node to remove the “split key” that previously separated these merged nodes — unless the parent is the root and we are removing the final key from the root, in which case the merged node becomes the new root (and the tree has become one level shorter than before).



### Example of insertion:

![B--inser.jpg](https://iq.opengenus.org/content/images/2018/06/B--inser.jpg.png)



### Example of deletion:

![b--deletion-1](https://iq.opengenus.org/content/images/2018/06/b--deletion-1.jpg)

### Complexity

- Worst case search time complexity: Θ(logn)
- Average case search time complexity: Θ(logn)
- Best case search time complexity: Θ(logn)
- Worst case insertion time complexity: Θ(logn)
- Worst case deletion time complexity: Θ(logn)
- Average case Space complexity: Θ(n)
- Worst case Space complexity: Θ(n)



# Bucket Sort

输入：

```python
def bucket_sort(A,min_value,max_value):
    buckets = [[] for i in range(min_value,max_value+1)]
    for x in A:
        buckets[x-min_value].append(x)
    sorted_arr = []
    for bucket in buckets:
        sorted_arr += bucket
    return sorted_arr

arr = [5,1,2,7,3,9,4,0,6,8]
sorted_arr = bucket_sort(arr,0,9)
print(sorted_arr)
```

输出：

```python
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
```



# Radix Sort

### Working of Radix Sort

1. Find the largest element in the array, i.e. max. Let `X` be the number of digits in `max`. `X` is calculated because we have to go through all the significant places of all elements.

   In this array `[121, 432, 564, 23, 1, 45, 788]`, we have the largest number 788. It has 3 digits. Therefore, the loop should go up to hundreds place (3 times).

2. Now, go through each significant place one by one.

   Use any stable sorting technique to sort the digits at each significant place. We have used counting sort for this.

   Sort the elements based on the unit place digits (x=0).

   ![Radix Sort working with Counting Sort as intermediate step](https://cdn.programiz.com/cdn/farfuture/uCNpqDxCh0fa6L5HIYKbmYCbiZHlGhzXXBsxKVpItSs/mtime:1591330108/sites/tutorial2program/files/Radix-sort-one.png)Using counting sort to sort elements based on unit place

3. Now, sort the elements based on digits at tens place.

   ![Radix Sort Step](https://cdn.programiz.com/cdn/farfuture/k2d_8gQeDKJ5pafc96mpZMqZvEqOOrh9eBCVmKRTBsg/mtime:1591330113/sites/tutorial2program/files/Radix-sort-ten.png)Sort elements based on tens place

4. Finally, sort the elements based on the digits at hundreds place.

   ![Selection Sort Step](https://cdn.programiz.com/cdn/farfuture/CvIF-W6hxb0-kwt-hn9Gb3IWlpTVxR3PK7X4TQimROc/mtime:1591330096/sites/tutorial2program/files/Radix-sort-hundred.png)Sort elements based on hundreds place



### Radix Sort Code

```python
# Radix sort in Python


# Using counting sort to sort the elements in the basis of significant places
def countingSort(array, place):
    size = len(array)
    output = [0] * size
    count = [0] * 10

    # Calculate count of elements
    for i in range(0, size):
        index = array[i] // place
        count[index % 10] += 1

    # Calculate cumulative count
    for i in range(1, 10):
        count[i] += count[i - 1]

    # Place the elements in sorted order
    i = size - 1
    while i >= 0:
        index = array[i] // place
        output[count[index % 10] - 1] = array[i]
        count[index % 10] -= 1
        i -= 1

    for i in range(0, size):
        array[i] = output[i]


# Main function to implement radix sort
def radixSort(array):
    # Get maximum element
    max_element = max(array)

    # Apply counting sort to sort elements based on place value.
    place = 1
    while max_element // place > 0:
        countingSort(array, place)
        place *= 10


data = [121, 432, 564, 23, 1, 45, 788]
radixSort(data)
print(data)
```

```python
[1, 23, 45, 121, 432, 564, 788]
```



# Hash table/ Hash function

A **hash function** is any function that can be used to map data of arbitrary size to fixed-size values. The values returned by a hash function are called *hash values*, *hash codes*, *digests*, or simply *hashes*. The values are usually used to index a fixed-size table called a **hash table**. Use of a hash function to index a hash table is called *hashing* or *scatter storage addressing*.

Hash functions and their associated hash tables are used in data storage and retrieval applications to access data in a small and nearly constant time per retrieval. They require an amount of storage space only fractionally greater than the total space required for the data or records themselves. Hashing is a computationally and storage space-efficient form of data access that avoids the non-linear access time of ordered and unordered lists and structured trees, and the often exponential storage requirements of direct access of state spaces of large or variable-length keys.

Use of hash functions relies on statistical properties of key and function interaction: worst-case behavior is intolerably bad with a vanishingly small probability, and average-case behavior can be nearly optimal.



First let's implement a (chained) hash table:

```python
class HashTable:
    # init function for our hash table
    # h is a function that maps a universe U to range(n)
    def __init__(self, h, n):
        self.h = h
        # store n buckets, each of which has a linked list. 
        # I'm just going to implement as python arrays.
        self.buckets = [ [] for i in range(n) ]
        
    def insert(self, x):
        self.buckets[self.h(x)].append(x)
        
    # delete an item in the hash table, if it's in there
    # returns the deleted item, or None if it wasn't found.
    def delete(self,x):
        bucket = self.buckets[self.h(x)]
        # take time O(n) to look for x in the bucket.
        for i in range(len(bucket)):
            if bucket[i] == x:
                return bucket.pop(i)
        return None
    
    # same as delete, but don't remove it when you find it.
    def find(self,x):
        bucket = self.buckets[self.h(x)]
        # take time O(n) to look for x in the bucket.
        for i in range(len(bucket)):
            if bucket[i] == x:
                return bucket[i]  
        return None
```





## Universal Hash Families

For a completely random hash function, we chose a function at random from the set {all of the functions}

Instead, we could choose a function at random from a smaller set.

### Not a good hash family

Here's the example from the slides

```python
def leastSigDig(x,n=10):
    return x%n

def mostSigDig(x,n=10):
    if x == 0:
        return 0
    while x > 0:
        last = x%n
        x = (x/n).__trunc__()
    return last

# our hash family will be { leastSigDig, mostSigDig }
```

### A better hash family

This is the universal hash family we saw in class

```python
def generateUniversalHashFn(a,b,p,n=10):
    # now define f.
    def f(x):
        r = (a*x + b) % p
        return r % n
    return f        

# our hash family is the set { generateUniversalHAshFn(a,b,p) : a=1,..,p-1, b=0,...,p-1 }
```
