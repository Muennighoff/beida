# 第十三堂学习小结

> **陈彦扬 2019080117 软件93**

##  文本分类

编码

```python
encoded_string = encoder.encode(sample_string)
print('Encoded string is {}'.format(encoded_string))
org_string = encoder.decode(encoded_string)
print('decode string is {}'.format(org_string))
```

模型

```python
model = tf.keras.Sequential([
    tf.keras.layers.Embedding(encoder.vocab_size, 64),
    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(1)
])
# 更多层
model = tf.keras.Sequential([
    tf.keras.layers.Embedding(encoder.vocab_size, 64),
    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,  return_sequences=True)),
    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(1)
])
```



## 文本生成

创建模型

```python
def build_model(vocab_size, embedding_dim, rnn_units, batch_size):
  model = tf.keras.Sequential([
    tf.keras.layers.Embedding(vocab_size, embedding_dim,
                              batch_input_shape=[batch_size, None]),
    tf.keras.layers.GRU(rnn_units,
                        return_sequences=True,
                        stateful=True,
                        recurrent_initializer='glorot_uniform'),
    tf.keras.layers.Dense(vocab_size)
  ])
  return model
```

预测循环

```python
def generate_text(model, start_string):
  # 评估步骤（用学习过的模型生成文本）

  # 要生成的字符个数
  num_generate = 1000

  # 将起始字符串转换为数字（向量化）
  input_eval = [char2idx[s] for s in start_string]
  input_eval = tf.expand_dims(input_eval, 0) #扩充维度，起始字符

  # 空字符串用于存储结果
  text_generated = []

  # 低温度会生成更可预测的文本
  # 较高温度会生成更令人惊讶的文本
  # 可以通过试验以找到最好的设定
  temperature = 1.0

  # 这里批大小为 1
  model.reset_states()
  for i in range(num_generate):
      predictions = model(input_eval)
      # 删除批次的维度
      predictions = tf.squeeze(predictions, 0)
      # 用分类分布预测模型返回的字符
      predictions = predictions / temperature #温度用来降低prediction的差距。
       #如果温度较高，类似于把概率差距很大的给降低，更容易抽到原来概率比较低的东西
      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()
      # 把预测字符和前面的隐藏状态一起传递给模型作为下一个输入
      input_eval = tf.expand_dims([predicted_id], 0) #对输入进行更新
      text_generated.append(idx2char[predicted_id])

  return (start_string + ''.join(text_generated))
```



## 语音识别

- 2014年11月,亚马逊推出了全新概念的智能音箱Echo。

- 2017年年底,全美共有超过4000万台智能音箱正在使用,其中亚马逊是3000万(Cirp数据)

- 2018年2月1日,美国智能音箱的线上市场份额, Echo全系列占比约70%,Echo show在Echo阵营中占比7% ( intelligence数据)

- 2020年中国占有全球智能音箱销售量的51%,位居全球第一。而同期美国的份额从44%下降到了24%。



#### “智能"+音箱

- 交互性:可以语音控制

- 灵性化:语音助手,可以对话交流等

#### 工作流程:

- 语音指令唤醒音箱

- 语音指令与提问录音,上传云端

- 云端处理:意图理解,生成问题的回答(文本)
- 回答返回音箱,语音合成,音箱播放



#### 智能音箱的核心技术:语音交互

- 语音识别

- 语音合成

- 自然语言处理

#### 语音识别(Automatic Speech Recognition) (ASR)

- 语音(信号波形) →文字(自然语言)

#### 语音合成(Text To Speech) (TTS)

- 文字(自然语言)语音(信号波形)

> 大致在2011年,基于深度学习的语音识别与语音合成技术的突破,使得智能音箱产业成为可能



语音识别资料：[https://cloud.tsinghua.edu.cn/d/5f0b4fd5d326423e8602/](https://gitee.com/link?target=https%3A%2F%2Fcloud.tsinghua.edu.cn%2Fd%2F5f0b4fd5d326423e8602%2F)



#### W= F(v, h)函数

> v代表语音信号,是t的函数(t, h1),其中h1是隐藏变量,
>
> w代表文字输出, h同样代表权重参数;



## 自动语音识别

ASR挑战问题：

- 语气、口气、强调、感情

- 说话方式

- 词汇表大小，同音字

- 噪声，录音质量

- 鸡尾酒会问题（cocktail party

  

语音信号表示

- 波形图
- 频率图
- 时频谱图 



评判指标

- 词错误率(word error rate) WER
  - 答案和识别结果对齐
  - 错误率等于 替换、插入、删除总数除以标准答案长度
  - 对齐应使错误率最小



### CTC

- CTC解决的问题
  - 对齐问题
- CTC原理
  - 对于给定的输入语音X
  - CTC给出所有可能的文字Y的分布
  - 并推断出可能的输出或者给定的输出文字Y的概率。
- CTC-loss损失函数
- CTC算法
- CTC-loss详细原理



### DeepSpeech 1-2-3

- 百度的DeepSpeech算法
- DeepSpeech2
- DeepSpeech2模型架构
- DeepSpeech2实现技巧
- 批归一化（Batch normalization)
- DeepSpeech开源实现
- DeepSpeech2-全中文语音识别
- TensorFlow2语音处理