# Pandas 基础

一维数据 Series、二维数据 DataFrame、三维数据 Panel

优点：比较好的统计学工具、容易可视化

https://pandas.pydata.org/pandas-docs/version/0.23/index.html



#### 一维数据结构 Series

- 可以储存任意数据类型
- 索引：index
- 调用方法 `s=pd.Series(data, index=index)`
- index长度必须与data一致

```python
import numpy as np
import pandas as pd
s=pd.Seires(np.random.randn(5), index=['a','b','c','d','e'])
```

- 向量化的操作（`s + s, s * 2, s[1:]+s[:-1]`）
-  `s[1:]`：从第二个到最后
- ``s[:-1]`：从倒数第二个到第一个



#### 二维数据结构 DataFrame

- 可以看做一个**Excel**表
- 调用方法：`s=DataFrame(data,index,columns)`
  - `data`：2D array、series的字典
  - `index`：用于指定行的label
  - `column`：用于指定列的label

```python
d={'one' : pd.Series([1.,2.,3.], index=['a','b','c']),
   'two' : pd.Series([1.,2.,3.,4.], index=['a','b','c','d'])}
df = pd.DataFrame(d)
df.index #show index
df.columns #show columns
```

- 如果指定了column，在字典找不到的值会出现`NaN`

```python
pd.DataFrame(d, index=['d','b','a'], column=['two','three'])
```

##### 列操作

```python
df["one"]
```

```python
df["three"] = df["one"] *df["two"]
df['flag'] = df["one"] > 2
```

<img src="https://i.imgur.com/jpcgF7M.png" alt="image-20211104175442918" style="zoom: 67%;" />

##### 操作csv文件

```python
pd.read_csv('abc.csv') #读取
pd.to_csv('abc.csv') #保存写入
```

##### 索引和选择

- **索引行需要加`loc`**

<img src="https://i.imgur.com/RaNvbjE.png" alt="image-20211104175659781" style="zoom:50%;" />

##### 时间序列

```python
dates=pd.date_rage('20200101',periods=6)
print(dates)
```

<img src="C:\Users\ILLEGEAR\AppData\Roaming\Typora\typora-user-images\image-20211104180006597.png" alt="image-20211104180006597" style="zoom:67%;" />

```python
df=pd.DataFrame(np.random.randn(6,4),index = dates, columns = list('ABCD'))
```

<img src="https://i.imgur.com/kwRucHm.png" alt="image-20211104180021798" style="zoom:67%;" />

##### 连接Pandas和SQLite

https://pandas.pydata.org/docs/user_guide/io.html#io-sql



# TensorFlow Playground

https://playground.tensorflow.org/



# 机器智能-深度学习

### 基本概念

- 深度学习$\subset$监督学习$\subset$机器学习
- 通常用于**分类**&**回归**
- 数据集、测试集、验证集
- 样本、标签
- 常见数据集：手写数字 MNIST 数据集、时尚 MNIST 数据集



##### Softmax 处理

所有输出的数值为正，所有分量之和为1

把计算完的特征变成概率分布相量
$$
g(z_m)=\frac{e^{z_m}}{\sum_k e^{z_k}}
$$


```python
import numpy as np
def softmax(x):
	x = np.exp(x)
	return x/np.sum(x)
x = np.arrange(1,10)
print(softmax(x))
```



##### 分对数 logit

把$(0,1)$内的数值变换到区间$(-\infty,+\infty)$

是sigmoid函数的反函数
$$
\sigma^{-1}(x)=\log(\frac{x}{1-x})
$$

```
logit = lambda x : np.log(x/(1-x))
```



### 自动化的权重确定

一般的流程：

1. 确定损失函数 (Loss)
2. 权重初始化 (Initialization)
3. 反向传播 (Back Propagation)
4. 权重修正 (Weights Adjusting)



### 损失函数

度量函数 $D(y,y')$：计算结果 $y$，标签 $y'$，差异值 $Delta$

1. 绝对值求和（Absolute Error) ${(|y_1-y_1'|+|y_2-y_2'|\dots)}$
2. 平均绝对值求和 (Mean Absolute Error MAE) $MAE=\frac{1}{n} \sum^n_{i=0} |y_i-\hat{y_i}|$
3. 平方和误差 (Squared Error)
4. ==均方差 (Mean Squared Error MSE)==
5. ==交叉熵 (Cross Entropy)==



#### 损失的数值化函数——度量函数

- 称为损失函数(Loss)
- 回归任务：均方误差 MSE
- 分类任务：交叉熵 CE
- 训练过程是损失函数的最小化过程



##### 均方差 MSE

```python
import numpy as np
import tensorflow as tf
y_true =[[0.,1.],[0.,0.]]
mse = tf.keras.losses.MeanSquaredError()
mse(y_true,y_pred).numpy()
```



##### 交叉熵 CE

$$
H_{y'}(y)=-\sum_i{y_i'\log{y_i}}
$$

似然：针对过去发生的事件

概率：未来某一世间发生的可能性

```python
y_true = [[0,1,0],[0,0,1]]
y_pred = [[0.05,0.95,0],[0.1,0.8,0.1]]
loss = tf.keras.losses.categorical_crossentropy(y_true,y_pred)
assert loss.shape == (2,)
loss.numpy()
```



## 反向传播算法

#### 损失函数的计算过程

<img src="https://i.imgur.com/5PDTEum.png" alt="image-20211104231254566" style="zoom:50%;" />

Loss简记为J

$y=h_n(\cdots h_3(h_2(W_2*h_1(W_1*X+b_1)+b_2)+b_3+\cdots b_n)$

$J=loss=D(y,y')$



##### 梯度计算

根据损失函数的性质及链式求导法则

反向逐层计算损失函数对权重的梯度（偏导数）

<img src="https://i.imgur.com/1GsgoKJ.png" alt="image-20211104231601046" style="zoom:50%;" />



##### 单个人工神经元（逻辑斯提回归单元）

反向求导

<img src="https://i.imgur.com/Fvs4ijw.png" alt="image-20211104232342290" style="zoom:50%;" />



## 权重更新

损失函数 Loss记为$J(\theta)$

沿着梯度方向行动一个步长 Step，再更新$\theta$值

步长又称学习率(learning rate)：太大会引起震荡，太小收敛太慢
$$
\theta = \theta - \eta \cdot \nabla_\theta  J(\theta)
$$
