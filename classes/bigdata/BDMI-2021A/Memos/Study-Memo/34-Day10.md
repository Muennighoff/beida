# 第十周

## 1 Python面向对象编程

### 1.类

**定义：**

    class mainclass:                   #类
        def __init__(self, a): #构造函数
            self.first = a
            self.last = 0
        def say():        #成员函数
            print('?')

    x = mainclass(0)                   #实例化
    x.say()                        #调用say函数   

### 2.继承

子类可以继承父类，拥有父类已经定义过的成员变量和成员函数，还可以对父类的成员函数进行重载

    class anotherclass(mainclass):
        def __init__(self, a, b):   #构造函数
            mainclass.__init__(self, a)
            self.middle = b

        def say():              #覆写成员函数
            print('!')

    child = anotherclass(1, 2)

方法覆写以后，可以通过super(anotherclass, child).say()调用覆写前的方法

**call:** 方法__call__()可以直接通过变量名调用

## 2 TF:模块、层、模型

### 1.模块

对张量进行前向运算

    class A_Module(tf.Module):
        def __init__(self, name=None):
            super().__init__(name=name)
            self.a=tf.Variable(1.0, name='a')
        def __call__(self, x)
            return self.a * x

### 2.层

可重用的参数结构

    class Dense(tf.Module):
        def __init__(self, in_features,out_features, name=None):
            super().__init__(name=name)
            self.w = tf.Variable(
                tf.random.normal([in_features, out_features]), name='w')
            self.b = tf.Variable(tf.zeros([out_features]), name='b')
        def __call__(self, x):
            y = tf.matmul(x, self.w) + self.b #张量运算
            return tf.nn.relu(y) #激活函数

### 3.模型

多连接层

    class SequentialModule(tf.Module):
        def __init__(self, name=None):
            super().__init__(name=name)
            self.dense_1 = Dense(in_features=3, out_features=3)
            self.dense_2 = Dense(in_features=3, out_features=2)

        def __call__(self, x):
            x = self.dense_1(x)
            return self.dense_2(x)

模型存储

    path="path"
    checkpoint=tf.train.Checkpoint(module=my_module)
    checkpoint.write(path)

模型恢复

    tf.train.list_variables(path)

### 4.tensorboard可视化

    %tensor --logdir logs/func

## 3 计算图

Graph：包含一系列tf计算的数据结构，可以用于计算的优化加速

### 1.建立

用一个函数初始化，得到计算图函数

    graph_func = tf.function(a_function)

tf.function可以递归跟踪所有调用的python函数，可以用 `%load_ext tensorboard`进行可视化

### 2.特点

计算图可以提高运算速度，但对于加速器上的运算作用不大

    tf.config.run_functions_eagerly(True) #全局不加速
    model.compile(run_eagerly=True) #不加速

## 4 tf训练

获取数据->定义模型->损失函数->运行并计算损失->梯度优化->评估

    #获取数据
    TRUE_W = 3.0
    TRUE_B = 2.0
    NUM_EXAMPLES = 1000
    # A vector of random x values
    x = tf.random.normal(shape=[NUM_EXAMPLES])
    # Generate some noise
    noise = tf.random.normal(shape=[NUM_EXAMPLES])
    # Calculate y
    y = x * TRUE_W + TRUE_B + noise

    #模型
    class MyModel(tf.Module):
        def __init__(self, **kwargs):
        super().__init__(**kwargs)
        # Initialize the weights to `5.0` and the bias to `0.0`
        # In practice, these should be randomly initialized
        self.w = tf.Variable(5.0)
        self.b = tf.Variable(0.0)

        def __call__(self, x):
            return self.w * x + self.b

    model = MyModel()

    #损失函数
    def loss(target_y, predicted_y):
        return tf.reduce_mean(tf.square(target_y - predicted_y))

    #梯度优化函数
    def train(model, x, y, learning_rate):
        with tf.GradientTape() as t:
            current_loss = loss(y, model(x))
            dw, db = t.gradient(current_loss, [model.w, model.b])
            model.w.assign_sub(learning_rate * dw)
            model.b.assign_sub(learning_rate * db)

    #循环训练
    def training_loop(model, x, y):
        for epoch in epochs:
            train(model, x, y, learning_rate=0.1)
            Ws.append(model.w.numpy())
            bs.append(model.b.numpy())
            current_loss = loss(y, model(x))

## 5 数据处理

### 1.tf.data读取数据

    tf.data.Dataset.from_tensor_slices(list) #从list读取数据
    tf.data.Dataset.from_tensor_slices(numpyarray) #从numpy读取数据
    tf.data.TFRecordDataset(file) #读取TFRecord数据
    tf.data.TextLineDataset(text_file) #读取文本数据
    tf.data.experimental.make_csv_dataset(file) #读取表格数据

基本处理：

    dataset.shuffle(buffer_size=100) #打乱数据
    dataset.map(function) #设置预处理函数
    tf.data.experimental.sample_from_datasets() #使数据类别平衡

### 2.图片处理

[文件](tfdata.ipynb)