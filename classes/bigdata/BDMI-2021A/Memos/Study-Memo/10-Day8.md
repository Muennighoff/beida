# Week 8 Summary

# 课程大纲
```
Python Pandas
TensorFLow2 Playground
Deep Learning II
二元分类（逻辑思提回归）
TensorFlow2基础
```

## Extra
> 第11周，组队分组
> 第8-15周：AI邀请赛（分类）

## Pandas 学习 （python data analysis library）
```
和numpy类似，但是有自己的特色
一维数据 series
二维 DataFrame
三维Panel

主要处理这三类数据，可视化情况好

pandas的数据是可变的数字长度

Series介绍：
	带标记的数组结构，可储存任意类型
	索引是index，默认从0开始，但是可以调成abc。。。
	s = pd.Series(data, index=index)
	后index示例：['a', 'b', 'c']
		index要和list的长度一样，不然会报错
	Series的向量操作与ndarray的表现一致
		加减乘除，取对数等操作都可以
	index不会随着操作进行改变
	
DataFrame介绍
	可以看作是excel工作表，SQL表等
	没有数据的地方会默认为NaN （使用时会报错）
	在进行向量操作的时候，NaN和其他数的任何操作都会得到NaN
	部分操作：
		df[col]			select column
		df.loc[label]	s row by label
		df.iloc[loc]	s row by integer location
		df[5:10]		slice row
		df[bool_vec]	s rows by bool
```

## TensorFlow Playground
```
学习率：过大会震荡，太小会收敛太慢
激活函数（activation）
噪声（noise）
problem type
	分类问题 classification
	回归问题 regression

```

## 机器智能 深度学习2
```
手写数字MNIST数据集（handwritten digits）
时尚MNIST数据集（识别衣物）
批量训练(batch traning)(现在都是指mini batch)
迭代 iteration
时代 epoch
。。。

Softmax 处理
	把整数变成加权为1的向量
分对数logit
	把0-1的数值变换到（-∞，+∞）
	是softmax的反过程 log(x/(1-x))
	
自动化的权重确定
	loss/ cost 定义损失函数
	initialization 权重初始化， 随机初始化（随机0-1的数字）
	back propagation 反向传播。计算损失函数对权重的梯度
	weight adjusting 权重修正 

损失函数：输出值与标签的差异
	损失的度量 一般是 MSE（回归任务） 或者 交叉熵（分类任务）

不同的度量函数：
	绝对值求和
	平均绝对值求和
	平方差误差
	MSE 均方差 （常用
	交叉熵 （常用
	
MSE:
	average((label - predict)**2)

交叉熵：
	负对数似然损失函数
	H (y) = - Σy'log(y)
	y'是标签，y是网络输出
	
反向传播算法(损失函数对权重的梯度计算)
梯度下降法（最优化算法）
	如果f(x)在a点可微且有定义，那么在a沿着梯度下降最快

反向传播的计算图

随机梯度下降法
	是一种稳定且有效的方法
	
```


## 神经网络的训练
### logistic regression 逻辑斯提回归实践
```
迭代：训练完一个迷你批次
时代：完成一个训练的过程
```