# 第九堂学习小结

> **陈彦扬 2019080117 软件93**

## Tensorflow

### 张量 (Tensor)

张量的实质是张量是**不可变化**的**N维数组**

- 0维Tensor的形式是标量，有0个轴
- 1维Tensor的形式是向量，有1个轴
- 2维Tensor的形式是矩阵，有2个轴
- 3维Tensor的形式是由矩阵组成的向量，有3个轴
- ......

#### 创建

```python
import numpy as np
import tensorflow as tf

tf.constant(
	value,
	dtpye=None,
	shape=None,
	name='Const',
	verify_shape=False
)

#2D tensor
rank_2_tensor = tf.constant(
    [[1,2,3,4],
     [4,5,6,7],
     [7,8,9,10],
     [10,11,12,13]])
print(rank_2_tensor)#4x4
```

#### 运算

```python
a = tf.constant([[1,2],[3,4]])
b = tf.constant([[5,6],[7,8]])
#对应元素相加
tf.add(a,b)
a + b
#对应元素相乘
tf.multiply(a,b)
a * b
#矩阵相乘
tf.matmul(a,b)
a @ b
```

```python
a = tf.constant([[1,2],[3,4]])
#寻找元素最大值
tf.reduce_max(a)
#求最大值的index
tf.argmax(a)
#对元素进行归一化处理
tf.nn.softmax(a)
```

```python
# 数据类型的转换
a = tf.constant([[1,2],[3,4]], dtype=tf.float64)
b = tf.cast(a,dtype=tf.float16)
c = tf.cast(b,dtype=tf.uint8)
```

```python
# 变换形状
aa=tf.constant([[1],[2],[3]])
bb=tf.reshape(aa,[1,3])
# 变成6x5
print(tf.reshape(rank_3_tensor,[3*2,5]),"\n")
# 变成3x10,-1代表剩下的自己排
print(tf.reshape(rank_3_tensor,[3,-1]))
```

```python
# Tensor 索引（index）
print('Everything',tensor[:].numpy()) 
print('Before 4',tensor[:4].numpy()) 
print('From 4 to end',tensor[4:].numpy()) 
print('From 2 to before 7',tensor[2:7].numpy()) 
print('Every even index',tensor[::2].numpy()) 
print('Reversed',tensor[::-1].numpy()) 
```

## 自动微分

### 梯度带 Gradient Tape

根据函数的输入变量计算它的导数

```python
x= tf.ones(2,2)

with tf.GradientTape() as t:
    t.watch(x) #加入记录带
   	y=tf.reduce_sum(x) #y=sum(x的所有元素)=4
    z=tf.multiply(y,y) #z=y^2=16
    
dz_dx=t.gradient(z,x)
    for i in [0,1]:
        for j in [0,1]:
            assert dz_dx[i][j].numpy() == 8.0  #如果assert是false，会报错
	
dz_dy = t.gradient(z,y)
assert dz_dy.numpy() == 8.0
```

#### 多次求导

```python
x = tf.constant(3.0)
with tf.GradientTape(persistent=True) as t:
    t.watch(x)
    y = x*x
    z = y*y
dz_dx = t.gradient(z,y) #108
dy_dx = t.gradient(x) #6.0
del t #用完过后要手动释放资源
```

#### 记录控制流

```python
x=tf.Variable(1.0)
with tf.GradientTape() as t:
	y = x*x +tf.exp(x)
dy_dx = t.gradient(y,x)
dy_dx.numpy()
```

#### 计算高阶导数

```python
x = tf.Variable(1.0)

with tf.GradientTabpe() as t1:
    with tf.GradientTabpe() as t2:
        y = x*x*x
    dy_dx=t2.gradient(y,x)
d2y_dx2=t1.gradient(dy_dx,x)

assert dy_dx.numpy() == 3.0
assert d2y_dx2.numpy() == 6.0
```

