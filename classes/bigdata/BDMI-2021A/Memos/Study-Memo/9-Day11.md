# 第11次课笔记


# 1 理论部分


## 1.1自动微分原理

目标(objective)：定义损失函数

训练(training)：计算损失对权重的偏导数

### 1.1.1 求导运算

**数值微分**：依据导数的定义来计算，因变量的差比上自变量的差，对自变量取极限。
缺点：有舍入误差，计算效率低。

**符号微分**：从表达式出发，使用诸多求导法则来计算。
例如，先相加再求导，相乘再求导，复合函数的链式法则等。
缺点：复杂程度随着函数表达式的复杂程度指数增加，需保存大量中间变量。

**自动微分**：两种方法。前向模式采用二元数方法，反向模式采用**反向计算图**方法。

### 1.1.2 计算图

**前向模式**：设置**某一个自变量**的初值后，沿着计算图一步一步向前，直到算出最终的输出值对**这个自变量**的导数。
从数学上来讲，相当于算出了自变量(x1, x2, ..., xn)到因变量(y1, y2, ..., yn)之间的雅克比行列式的第一列。即全部因变量对**某一个**自变量的导数。

**反向模式**：设置**某一个因变量**对自己的导数的初值，从计算图的输出端，反向前进，直到算出对**所有自变量**的导数。
也就是说，算出了雅克比行列式的一行。即某个因变量（可以是损失函数）对所有因变量的（所有权重）的导数。这正是深度学习需要的。

**反向传播**：是神经网络执行梯度下降法的主要算法。
反向传播，和自动微分的反向模式本质是一样的。


## 1.2 深度神经网络的架构

多层神经网络，就称为深度神经网络。

网络的拓扑结构：（多层人工神经网络不同层神经元之间的）**连接关系**。
按不同连接关系，可分为前馈网络、反馈网络、记忆网络。
图网络：与计算图要区分开。

一种连接方式是**全连接**：又称密集连接（Dense），每层神经元和下一层的神经元全连接，包括输入层和隐藏层，隐藏层和隐藏层，等等。


## 1.3 深度卷积网络结构

Convolutional Neural Network
**卷积网络属于前馈网络的典型结构。**
 
**基本结构**：卷积层、池化层、归一化层

卷积网络也有所谓的拓扑结构。与全连接不同，卷积网络是**局部的，稀疏**的连接。

### 1.3.1 卷积核与卷积运算

**卷积核**：一个多维数组

**卷积运算**：对输入的多维数组数据，采用卷积核的过程。
输入多维数组，可以看做张量。卷积核也可以看做张量。卷积运算是一种张量运算。
具体的，将卷积核在多维数组上面移动。

**无填充式、有填充式**：
有填充式，不局限于被卷积图像本身。可以用0扩充被卷积图像的边界。

**3d卷积运算**：
采用3D卷积核，和3D的输入张量进行卷积运算。
如果第三维度相同，则卷积结果是一个2D的平面。
如果采用多个3D卷积核，则得到3D的结果。

### 1.3.2 下采样层

每个卷积层后通常紧跟着一个下采样层。作用是：用来缩小输出张量的大小。

下采样的方法有：最大池化（取最大值）、平均池化（取平均值）。

### 1.3.3 归一化层

有时在卷积运算后，添加归一化层，或称为正则化层（normalization layers）。

例如：LCN层（local contrast normalization）。
作用：减去平均层，除以标准差。
一般LCN操作在最大池化操作之后。

## 1.4 卷积网络的层间连接

卷积核的运算，等效为局部规则连接。和全连接网络Dense的全连接是区别开的。

## 1.5 卷积网络的发展

LeNet-5：手写字体识别
AlexNet：百万图片的分类

AlexNet -> NiN -> VGG -> GoogleNet -> ResNet -> DenseNet

## 1.6 卷积网络应用

应用于图像分类的优点：
相比于MLP，参数少；并行化；运算快。


# 2 Keras

何为Keras？
是一套高级API（应用程序接口），可用来快速搭建深度神经网络。

如何用Keras实现卷积网络，并进一步实现图像分类？

tensorflow.keras，是基于TensorFlow2，实现快速搭建深度神经网络的程序库。

```python
import tensorflow as tf
from tensorflow import keras
```

## 2.1 一些核心概念

keras的核心数据结构：模型（Model）

### 2.1.1 层和模型

模型是组织层的一种方式，包括架构（连接关系）和权重参数。

```python
tf.keras.layers
```

常见的Keras层（layers）包括：


顺序模型是最简单的Model类型。
https://tensorflow.google.cn/guide/keras/sequential_model

**定义一个3层的顺序模型：**
```python
# Define Sequential model with 3 layers
model = keras.Sequential(
    [
        layers.Dense(2, activation="relu", name="layer1"),
        layers.Dense(3, activation="relu", name="layer2"),
        layers.Dense(4, name="layer3"),
    ]
)
# Call model on a test input
x = tf.ones((3, 3))
y = model(x)
```

**Layer类**：权重和部分计算的组合。

Keras的一个中心抽样是Layer类。


### 2.1.2 激活函数

### 2.1.3 优化器



## 2.2 Keras使用流程

定义网络、网络编译、网络训练、评估网络、数据预测、保存、载入网络


## 2.3 顺序模型

适用于普通堆栈的图层。每个图层只有一个输入张量和一个输出张量。
等价于采用全连接层。
不适用于：模型、层有多个输入或多个输出；图层共享；非线性拓扑。

### 2.3.1 顺序模型的创建

方法一：使用顺序构造函数
```python

```

方法二：通过add()以增量方式创建
```python

```

可接受name参数，用于层的注释。

### 2.3.2 预先指定输入形状

shape = (4,1)和shape = (4,)有什么区别？
前者是2D张量，后者是1D。

### 2.3.3 基于顺序模型的迁移学习

包括：冻结模型的底层，只训练顶层。

## 2.3 模型的保存和加载

```python
model.save("my_model")

keras.models.load_model("my_model")
```
会创建一个名为my_model的文件夹。含有三个文件：assets、saved_model1.pb、variables。

模型的架构、训练配置（包括优化器、损失、指标）存储在saved_model.pb中；
权重保存在variables目录下。

### 2.3.1 保存架构

```python
config = model.get_config()
#返回包含模型配置的字典

from_config()
```

### 2.3.2 仅保存和加载模型的权重值



## 2.3 卷积网络实现鲜花数据集的分类

详情见：
image_classification.ipynb