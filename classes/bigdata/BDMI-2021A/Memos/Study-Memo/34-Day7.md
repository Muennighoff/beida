#第七周

##1 Numpy基础

**数组创建：** `array()` 可用tuple、list作参数进行初始化，通过dtype option设置数据类型

	f = numpy.array([[1,2,3],[1,2,3]]), dtype=complex)

**算术运算：** array可以与标量进行运算，相当于其中每一个元素均进行相应运算；还可以与array进行标量运算，相当于对应元素进行相应的标量运算。

	a = numpy.array([1,2,3,4])
	b = numpy.array([1,0,0,0])
	a + 2 #[3,4,5,6]
	a * b #[1,0,0,0]

算术运算中可以嵌套各种各样的函数运算符 `sin` `sqrt` 等

**矩阵运算：** `reshape()`重构；`ones()`全是1的矩阵；`dot()`矩阵乘法；`zeros`零矩阵；`identity()`单位矩阵；

##2 人工神经元

**神经元：**一组输入的线性加权叠加后经过一个非线性变换输出

**激活函数：**`sigmoid()` `tanh()` `ReLU()`

	def sigmoid(x):
		return 1/(1+exp(-x))

	def tanh(x):
		return (exp(2*x)-1)/(exp(2*x)+1)

	def ReLU(x):
		return max(x,0)

加权后的神经元：

	w = [0.1, 0.4, -0.9] #权重
	result=ReLU(w*a)

**模拟布尔运算：**利用激活函数可以设计权重模拟布尔运算

或：[a,b] -> [a,b,1] * [20,20,-10];非：[x] -> [x,1] * [-20, 10]...

多个神经元可以模拟更复杂的运算，如多个神经元模拟异或运算（相当于化为合取（析取）范式以进行门的复合）

##3 神经网络

**机器学习：**根据输入数据训练预测模型，主要有监督学习、非监督学习、强化学习等；典型的任务有分类任务和预测任务；神经网络方法是监督学习的一种方法，多层神经网络又称深度神经网络。

**神经网络：**单个神经元可以解决二分类问题，更复杂的问题要通过多层网络解决；包括输入层、隐藏层、输出层；其中的多元分类可以归一化为概率向量。

	def SoftMax(x):
		return exp(x)/sum(exp(x))

