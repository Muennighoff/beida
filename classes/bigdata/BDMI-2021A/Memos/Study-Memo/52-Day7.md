# BDMI Day7

`Student No.52`

## Numpy

`np.dot()` 是求内积， `np.sum()` 是求和

- 数组变形
  - reshape()：转换数组的形状，返回新的数据对象
  - ravel()：将高维数组转为一维数组
  - transpose()：调换数组的行与列的索引值

## 人工神经元

本质：一组输入的线性加权叠加之后，经过一个非线性变换输出

* 激活函数，常见的有：

  * Sigmoid函数
    $$
    sigmoid(x)=\frac{1}{1+e^{-x}}
    $$

  * tanh函数
    $$
    tanh(x)=\frac{e^x-e^{-x}}{e^x+e^{-x}}
    $$

  * Relu函数
    $$
    Relu(x)=max(x,0)
    $$
    
  * https://feisky.xyz/machine-learning/neural-networks/active.html

* 能力

  * 单个：进行布尔运算，与或非；二元分类
  * 多个：XOR等多重布尔运算；多元分类

## 机器学习

**机器学习按学习的方式来划分，**主要包括：

- 监督学习：输入数据带有标签。监督学习建立一个学习过程，将预测结果与 “训练数据”（即输入数据）的实际结果进行比较，不断的调整预测模型，直到模型的预测结果达到一个预期的准确率，比如分类和回归问题等。常用算法包括决策树、贝叶斯分类、最小二乘回归、逻辑回归、支持向量机、神经网络等。
- 非监督学习：输入数据没有标签，而是通过算法来推断数据的内在联系，比如聚类和关联规则学习等。常用算法包括独立成分分析、K-Means 和 Apriori 算法等。
- 半监督学习：输入数据部分标签，是监督学习的延伸，常用于分类和回归。常用算法包括图论推理算法、拉普拉斯支持向量机等。
- 强化学习：输入数据作为对模型的反馈，强调如何基于环境而行动，以取得最大化的预期利益。与监督式学习之间的区别在于，它并不需要出现正确的输入 / 输出对，也不需要精确校正次优化的行为。强化学习更加专注于在线规划，需要在探索（在未知的领域）和遵从（现有知识）之间找到平衡。

**机器学习按功能划分**，主要是2类，分类与回归：

**分类（Classification）**是一种对离散随机变量建模或预测的监督学习算法。分类通常基于回归方法扩展，适用于预测一个类别（或类别的概率）而不是连续数值。

常用的分类方法包括

- 逻辑回归：对应线性回归方法，但使用了Sigmoid函数将预测映射为0到1之间的数值
- 分类树：对应回归树，又称为分类回归树（CART），将数据集分割为不同分支而实现分层分类
- 深度学习：使用多层神经网络分类
- 支持向量机（SVM）：基于核函数计算支持向量之间的距离，并寻找最大化其与样本间隔的边界
- 朴素贝叶斯：基于贝叶斯定理和特征条件独立假设的分类方法

**回归（Regression）**是对数值型连续随机变量进行预测和建模的监督学习算法。其特点是标注的数据集具有数值型的目标变量。

常用的回归方法包括

- 线性回归：使用超平面拟合数据集
- 最近邻算法：通过搜寻最相似的训练样本来预测新样本的值
- 决策树和回归树：将数据集分割为不同分支而实现分层学习
- 集成方法：组合多个弱学习算法构造一种强学习算法，如随机森林（RF）和梯度提升树（GBM）等
- 深度学习：使用多层神经网络学习复杂模型

---

* 机器学习的主要三种范式
  * 监督学习1：决策树、决策森林、支撑向量机、贝叶斯分类器、核方法、逻辑回归；
  * 监督学习2：神经网络、全连接网络、卷积网络、循环网络；
  * 非监督学习：降维方法（PCA，自动编码器，主题模型）、聚类
  * 强化学习：策略梯度、深度Q网络、Actor-Critic算法
* 监督学习
  * 两阶段：训练、推断
  * 特点
    * 训练集由样本组成，每个样本上有对应的标签，用来指导学习
    * 根据训练集的样本进行学习，推断出新的实例
* 深度学习
  * 神经网络方法属于监督学习的一种
  * 多层神经网络又称为深度神经网络
  * 深度神经网络又称为深度学习
