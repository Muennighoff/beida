# Keras 循环网络

## 文本识别

使用电影评论数据集，判断一条评论是积极的还是消极的。

核心步骤为：

### 编码

```python
encoded_string = encoder.encode(sample_string) #dataset的数据类型无法直接放入神经网络，所以需要编码。
#encoder: 可以以可逆的方式对任何字符串进行编码
print('Encoded string is {}'.format(encoded_string))
```

### 主体模型

```python
model = tf.keras.Sequential([
    tf.keras.layers.Embedding(encoder.vocab_size, 64),
    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)), #一个一层的全连接神经网络
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(1)
])
```

也可以堆叠更多的LSTM层

```python
model = tf.keras.Sequential([
    tf.keras.layers.Embedding(encoder.vocab_size, 64),
    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,  return_sequences=True)),
    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(1)
])
```

## 文本生成

使用莎士比亚作品，通过一个开头生成一段莎士比亚风格的文字。

本质是通过一段词条，预测下一个字符。

核心步骤为：



### 创建映射

```python
# 创建从非重复字符到索引的映射
char2idx = {u:i for i, u in enumerate(vocab)}
idx2char = np.array(vocab) #通过索引把字符映射回来

text_as_int = np.array([char2idx[c] for c in text])
```

### 主体模型

```python
def build_model(vocab_size, embedding_dim, rnn_units, batch_size):
  model = tf.keras.Sequential([
    tf.keras.layers.Embedding(vocab_size, embedding_dim,
                              batch_input_shape=[batch_size, None]),
    tf.keras.layers.GRU(rnn_units,
                        return_sequences=True,
                        stateful=True,
                        recurrent_initializer='glorot_uniform'),
    tf.keras.layers.Dense(vocab_size)
  ])
  return model
```

### 对输出的处理：模型卡死解决方案

```python
# dense中输出65个，然后依据每个的预测概率对它们进行抽样。
#这样有一个好处：如果只是选取dense输出最大者，很有可能会在几个字符中卡死（比如总是认为e下一个大概率是s，s下一个大概率是e。输出就变成eseses）
sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)
sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()
```

### 预测循环

```python
def generate_text(model, start_string):
  # 评估步骤（用学习过的模型生成文本）

  # 要生成的字符个数
  num_generate = 1000

  # 将起始字符串转换为数字（向量化）
  input_eval = [char2idx[s] for s in start_string]
  input_eval = tf.expand_dims(input_eval, 0) #扩充维度，起始字符

  # 空字符串用于存储结果
  text_generated = []

  # 低温度会生成更可预测的文本
  # 较高温度会生成更令人惊讶的文本
  # 可以通过试验以找到最好的设定
  temperature = 1.0

  # 这里批大小为 1
  model.reset_states()
  for i in range(num_generate):
      predictions = model(input_eval)
      # 删除批次的维度
      predictions = tf.squeeze(predictions, 0)

      # 用分类分布预测模型返回的字符
      predictions = predictions / temperature #温度用来降低prediction的差距。
        #如果温度较高，类似于把概率差距很大的给降低，更容易抽到原来概率比较低的东西
      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()

      # 把预测字符和前面的隐藏状态一起传递给模型作为下一个输入
      input_eval = tf.expand_dims([predicted_id], 0) #对输入进行更新

      text_generated.append(idx2char[predicted_id])

  return (start_string + ''.join(text_generated))
```



## 语音控制方案实现

使用智能公元平台（http://smartpi.cn/#/）进行实现，主要包括如下几个过程：

* 设置各类关键词：包括唤醒和具体操作。整个模块通过提取语言关键词进行反应和触发。由于是离线方案，无法识别较为复杂和模糊的语言。
* 设置控制方式和其他参数：这里定义了提取到关键词后的具体反映方式和反应行为。在本方案中应以*端口输出*。
* 获取语音模块，并将生成的SDK导入其中，以实现整个语音控制过程。

语音识别模块资料：https://cloud.tsinghua.edu.cn/d/5f0b4fd5d326423e8602/

## 语音识别

在2006年左右，纯深度学习模型在表现上超过经典方法。

自动语音识别（Automatic Speech Recognition, ASR）

自然语言处理（Natural Language Processing, NLP）

ASR的主要挑战：

* 语气、口气、强调、感情
* 说话方式
* 词汇表大小，同音字
* 鸡尾酒会问题（cocktail party）：多个人同时说话
* 噪声，录音质量

### 数据

波形图：时间序列波形

频域图：快速傅立叶变换后的波形图

时频谱图：以某个单位（比如100毫秒）为一个窗口获得信号，并进行傅立叶变换

时频谱图优点：保留了时间和频域的信息

### 评价标准

词错误率（Word Error Rate WER）

基于最优对齐方法：在最优对齐之后，计算如下数值
$$
WER=\frac{需要替换、插入、删除的错误词个数}{标准答案的词总数}
$$
需要注意；WER可能高于100%（比如所有词都判断错了，还多判断了一个词）

### 深度学习方法

<img src="4-Day13.assets/截屏2021-12-08 下午3.36.45.png" alt="截屏2021-12-08 下午3.36.45" style="zoom:67%;" />

### CTC：连接主义的时间分类

解决了语音对齐问题：到底哪个字对应哪段波

对于给定的输入语音X，CTC给出所有可能的文字Y的分布，并推断出可能的输出或者给定的输出文字Y的概率。

