# 第九周
## 1 TF2:张量

### 1.创建

    r0 = tf.constant(4) #零维
    r1 = tf.constant([1,2,3]) #一维
    r2 = tf.constant([1,2], [3,4], [5,6]) #二维
    r2 = tf.constant([[1,2], [3,4], [5,6]], dtype=tf.float16) #二维+类型标定

三维以及更高维可同理创建，也可由numpy数组初始化生成。

### 2.运算

**类型转换**

    np.array(r2) #张量转numpy数组
    r2.numpy() #返回值为numpy数组

**四则运算**

    tf.add(a, b) #返回张量之和
    tf.multipply(a, b) #返回张量之积
    tf.matmul(a, b) #返回矩阵乘法结果

**张量的特殊运算**

    tf.reduce_max(a) #返回最大元素
    tf.argmax(a) #返回最大元素的索引
    tf.nn.softmax(a) #返回归一化之后的结果
    tf.cast(a, dtype=int32, name=None) #类型转换
    tf.reshape(a, shape=(1,3), dtype=int32) #变形处理

此外，在一定条件下，tensor最一组向量执行组合运算时，为了适应大张量会对小张量进行“扩展”，称为“广播”。

**索引**

索引规则与数组基本相同

        r2[0] #第1项
        r2[-1] #最后一项
        r2[:] #所有
        r2[1:5] #标号1到5项
        r2[::2] #间隔取出
        r2[::-1] #逆序
        r2[1, :] #多轴切片

### 3.特殊张量

**不规则张量**：张量轴上元素个数可变

    tf.ragged.RaggedTensor(a) #用a初始化一个不规则张量

**字符串张量**

    tf.constant("aa bb cc") #零维字符串张量
    tf.strings.split(a) #字符串张量分割
    tf.strings.byte_split(a) #转换为字节张量
    tf.io.decode_raw(a) #依照编码方式转化为数值张量

**稀疏张量**

    a = tf.sparse.SparseTensor(indices = [[0,0],[1,3]], values=[1,2], dense_shape=[3,4]) #返回稀疏张量
    tf.sparse.to_dense(a) #生成对应的普通张量

## 2 TF2:变量

**创建**

    tf.Variable(tensor) #常量做初值创建变量

**运算**：与张量类似有 `shape` `dtype` `numpy` 等运算

**修改**： `assign`，注意需保证形状不变

    a.assign([1,2]) #修改为[1,2]
    a.assign_add([1,2]) #增加[1,2]

**其他**：`tf.Variable(1,trainable=False)`关闭梯度

### 4.梯度微分

**梯度带：** `tf.GradientTape()` 记录上下文中的有关操作，在需要运算时反向微分来求得导数

    with tf.GradientTape() as t:#建立Tape
        t.watch(x)
        y = tf.reduce_sum(x)
        z = tf.multiply(y,y)
        dz_dy = t.gradient(z,y) #求导

多次计算要用到persistent:

    with tf.GradientTape()(persistent = True) as t:#建立Tape
        t.watch(x)
        y = tf.reduce_sum(x)
        z = tf.multiply(y,y)
        dz_dy = t.gradient(z,y) #求导

还可以进行嵌套计算高阶导数：

    with tf.GradientTape() as t1:
        with tf.GradientTape() as t2:
            y=x*x
            d1=t2.gradoent(y, x)
            d2=t1.gradient(d1,x)