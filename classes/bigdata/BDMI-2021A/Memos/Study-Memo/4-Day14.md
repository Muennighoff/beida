# 计算机视觉原理

[TOC]



## 人类感知

视觉：依赖大脑皮层的不同区域（Cortex）

Rod cells 负责明暗视觉；Cone cells负责彩色细胞

色彩处理细胞比黑白处理细胞显著少。

细胞处理视觉分为两层，前一层处理特征，后一层进行整合——启发了人工神经网络

## 计算机视觉

使用计算机来处理图像和视频。

主要挑战：自动抽取图片的信息。

主要应用场景：自动驾驶（Self-Driving/Driverless），分很多级别；辅助驾驶（ADAS），通过决策算法，运用传感器，观察周围环境信息，辅助驾驶员。

### 英伟达自动驾驶

道路感知（以头部公司英伟达方案为例）

* LaneNet 预测车道线
* PathNet 预测可运行的路径边线
* Wait Conditions 等待条件，判断何时需要等待
* PilotNet 预测人类的运行轨迹

### 特斯拉自动驾驶

全自动驾驶（FSD， Full Self-Driving）

原理为纯视觉算法（HydraNet），输入为八个摄像头的环境感知。基于深度卷积网络进行内容识别。

## 计算机视觉的任务（Visual Task）

分类（是什么）、定位（在图片中何处）、检测（图片中有多少物体，在哪里）、分割（将图片中的物体逐个扣出）

### 精确率 Precision

指针对预测结果而言的精确率。在*二元分类*问题中：

* 把正类预测为正TP
* 把负类预测为正FP

$$
Precision = \frac{TP}{TP+FP}
$$

### 召回率 Recall

指针对原来的样本而言。表示样本中的正例有多少被预测正确了。

* 把原来的负类预测为负类TN
* 把原来的正类预测为负类FN

$$
Recall = \frac{TP}{TP+FN}
$$

### 准确率 Accuracy

指针对给定的测试数据集，分类器正确分类的样本数/总样本数。
$$
Accuracy = \frac{TP+TN}{TP+FN+FP+TN}
$$
其他常见的指标比如AUC、混淆矩阵等。

## 基于深度学习的计算机视觉

自AlexNet以来的良好表现。

OD算法：对象检测

### 视觉对象检测的指标

与分类任务的指标有区别。

#### IOU 重叠联合比

表示预测框和真实框的重叠联合比。即交集/并集。
$$
\text { IOU }_{\text {pred }}^{\text {truth }}=\frac{\text { Area of Intersection }}{\text { Area of Union }}
$$

#### 正确的对象检测

标准：预测对象正确（Correct），且$IOU>0.5$

其余皆乘坐错误的对象检测。

### R-CNN算法

流程：

1. 首先，利用选择性搜索算法提取候选区域
2. 使用卷积神经网络对候选区域提取深度特征
3. 通过SVM分类器对每个候选区域进行分类识别

一个优点是迁移学习效果好。

变种：Fast R-CNN，相比原种更为简洁。主要思路为最终使用一个卷积网络来确定物体位置。

### YOLO算法 You Only Look Once

将对目标的检测从*分类问题*转变为*回归问题*。优点：运算很快，可以实时部署。

思路：将图片放入一个网格图，并判断每个网格内是否有所需目标。最终将同一类的网格合并为一个区域。给出目标区域。

24个卷积层后接2个全连接层。

存在漏检问题（尤其是多个小目标成群的样本），并且准确性不如Faster R-CNN。

### SSD算法

类似YOLO，将特征图切成小网格，使用CNN得到一个个小框，并给框内对象打分。

基于前向传播的CNN网络，产生一系列固定大小的边界框，并计算每个框中的对象实例可能性分数。

## Tensorflow2 Hub

网站：https://tensorflow.google.cn/hub

https://hub.tensorflow.google.cn/

一个训练好的模型，可以进行：图像分类、文本分类、风格迁移、对象检测、图像生成、超分辨率、图片扩展、音高识别、声音分类

问题：模型过于泛化，故需要使用模型进行二次训练，来进行具像化预测。（比如Hub可以识别树，但无法识别具体是什么树）。

使用迁移学习，迁移到一个具体的子数据集中。



