# 课后小结第七周

## 一、Numpy库

#### 1. 创建数组和数据类型定义

```python
import numpy as np

a = np.array([[1,2,3],[4,5,6]])							#创建一个数组，接受tuples()和list[]，并且可以混合
b = np.array(((1,2,3),(4,5,6)))
c = np.array([[1,2,3],[4,5,6]], dtype = complex)		#可以使用dtype设置数据类型						

d = np.empty((a,b,c))									#创建a页b行c列的数组，其元素均为随机值/1/0
f = np.ones((a,b,c))									#且a，b均可省略（省略时默认为1）
g = np.zeros((a,b,c))									
```



#### 2. 运算

```python
import numpy as np

a = np.arange(a,b,c)	    	#以a为起点，b为上限，c为步长创建一维数组
								#a、c可以省略（省略时默认为a=0,c=1），省略1个参数时为省略c		

#数组与标量（scalar）的算术运算
a = np.arange(4)				# a = [0, 1, 2, 3]
a + 4							# a = [4, 5, 6, 7]
a * 2							# a = [0, 2, 4, 6]

#数组之间的算术运算
b = np.arange(4, 8)				# b = [4, 5, 6, 7]
a + b							# array([4, 6, 8, 10])
a - b							# array([-4, -4, -4, -4]) 

#函数运算
np.sin(b)						#对数组内的每个元素进行对应的函数运算
np.sqrt(b)

#矩阵乘积
A * B							#矩阵内各个元素对应相乘
np.dot(A,B)						#两个矩阵进行矩阵相乘

#增减算符
#python内没有++与--的算符，使用+=、-=、*=

```

#### 3. 数组变形

```python
a = np.random.random(12)		#生成12个随机数并组成一维数组，也可以生成高维数组

#reshape()
A = a.reshape(3, 4)				#将数组变形为3行4列的形式，并返回新的数组
a.shape							#查询数组的形状，也可以通过规定形状的方式来操作数组
a.shape = (3, 4)				

#ravel()
a.ravel()						#将数组展平并返回新数组，order规定按行（'C'）还是列（'F'），省略时默认按行展平
a.ravel(order = 'F')

#transpose() 矩阵转置
a.transpose()					#将数组转置并返回新数组
```

#### 4. 常用命令

```python
#Numpy使用
np.matmul(a, b)					#a和b进行矩阵相乘，在二维情况下与dot得到的结果相同，但在三维情况下不同	
np.identity(n)					#创建一个n*n的单位矩阵		
np.vstack(a, b)					#将a、b矩阵水平堆叠
np.hstack(a, b)					#将a、b矩阵垂直堆叠

#Numpy调试
array.ndim						#返回数组的维度
array.shape						#返回数组的形状
array.dtype						#返回数组的数据类型
type(stuff)						#获取变量的类型
import pdb;ped.set_trace()		#设置断点
```

+ pdb常用命令

  ![pdb常用命令](C:\Users\zhouyao\Desktop\学习\大三上\大数据与机器智能\pdb常用命令.png)

## 二、人工神经元

+ 单个人工神经元

  一组输入的线性加权叠加经过一个非线性变换进行输出

#### 1. 激活函数

+ Sigmoid函数

  逻辑斯提函数(logistic function)或S形函数，表达式为
  $$
  sigmoid(x) = \frac{1}{1+e^{-x}}
  $$
  代码实现

  ```python
  def sigmoid(x):
      return 1 / (1 + np.exp(-x))
  ```

+ tanh函数或th函数

  双曲正切函数，表达式为
  $$
  tanh(x) = \frac{e^x-e^{-x}}{e^x+e^{-x}}
  $$
  代码实现

  ```python
  def tanh(x):
      return (np.exp(x) - np.exp(-x))/(np.exp(x) + np.exp(-x))
  ```

  

+ ReLU函数

  整流线性单元，表达式为
  $$
  ReLU(x)=max(x, 0)
  $$
  代码实现

  ```python
  def relu(x):
      if x > 0:
          return x
      else:
          return 0
  ```

#### 2. 布尔运算

```python
#与运算（AND）
def my_and(a, b):
    A = np.array([a, b])
    B = np.array([20, 20])
    c = -30
    return round(sigmoid(np.matmul(A, B) + c))

#或运算（OR）
def my_or(a, b):
    A = np.array([a, b])
    B = np.array([20, 20])
    c = -10
    return round(sigmoid(np.matmul(A, B) + c))

#非运算（NOT）
def my_not(a):
    return round(sigmoid(-20 * a + 10))

#与非运算（NAND）
def my_nand(a, b):
    A = np.array([a, b])
    B = np.array([20, 20])
    c = 30
    return round(sigmoid(c - np.matmul(A, B)))

#异或运算（XOR）
def my_xor(a, b):
    return my_and(my_or(a, b), my_or(my_not(a), my_not(b)))

```

## 三、多层神经网络

#### 1. 机器学习

Machine Learning，简称ML，根据输入数据构建（训练）预测模型

+ 机器学习的主要三种范式：
  + 监督学习-1：决策树、决策森林、支撑向量机、贝叶斯分类器、核方法、逻辑回归
  + 监督学习-2：神经网络、全连接网络、卷积网络、循环网络
  + 非监督学习：降维方法（PCA，自动编码器，主题模型）、聚类
  + 强化学习：策略梯度、深度Q网络、Actor-Critic算法

+ 数据集
  + 训练集（training set）：数据集的子集，用于训练模型
  + 验证集（validation set）：数据集的子集，从训练集分离而来，用于验证学习效果
  + 测试集（test set）：数据集的子集，用于在模型经由验证集的初步验证之后测试模型

+ 机器学习的应用

  机器学习主要用于解决两类任务

  + 分类任务：通过对数据集的学习，对新数值进行集合分类
  + 预测任务：通过对数据集的学习，预测新的数值

#### 2. 监督式机器学习

+ 方法：在给定输入和输出对(x, y)的情况下，监督学习学习映射f（或给定输入x情况下输出y的概率分布）
+ 特点
  + 根据训练数据集中的样本进行学习，然后推断新的实例
  + 训练数据集有样本组成，每个样本上都有对应的标签，用来指导学习过程

+ 阶段

  监督学习分为训练和推断两个阶段

#### 3. Softmax处理

输出层的Softmax处理，计算出一个概率分布向量

+ 所有输出的数值都是正的，所有分量之和为1。

$$
g(z_m)=\frac{e^{z_m}}{\sum_k e^{z_k}}
$$

代码实现如下

```python
def softmax(x):
    x = np.exp(x)
    return x / np.num(x)
```

