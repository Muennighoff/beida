# 第10次课笔记

# 1 Python面向对象编程

## 1.1 类

### 1.1.1 概述

类（Class）：抽象化的定义
对象（Object）：类的实例化
属性（Attribute）：类的变量
方法（Method）：类的函数
参数（Parameters）：
实例化（Instance）：创建一个类的对象的过程

### 1.1.2 简单例子 Myclass

```python
class MyClass:
	i = 123456 #类的属性。就是类里面定义的一堆变量
	def f(self): #类的方法。就是类里面定义的一堆函数。self是对自己类的调用
		return 'hello world'

x = MyClass() #实例化
print(x.i) #访问类的属性
print(x.f()) #访问类的方法
```

### 1.1.3 类 __init__函数

```python
class Complex:
	def __init__(self, realpart, imaginary): 
	#构造函数，self是对实例化的类的调用
		self.r = realpart
		self.i = imaginary

x = Complex(3.0, -4.5) #调用实例化类的构造函数，传入相应的参数完成实例化
print(x.r, x.i) #调用类的属性
```

## 1.2 Vehicle类和Dog类的例子

```python
class Vehicle:
	def __init__(self,make,name,year,is_electric=False,price=100):
		self.name = name
		self.make = make
		self.year = year
		self.is_electric = is_electric
		self.price = price
		
		self.odometer = 0
	
	def drive(self,distance):
		self.odometer += distance
	
	def compute_price(self):
		if self.is_electric:
			price = self.price / (self.odometer * 0.8)
		else:
			price = self.price / self.odometer
		return price

if __name__ == '__main__':
	family_car = Vehical('Honda','Accord','2019',price=10000)
	print(family_car.compute_price)
	family_car.drive(100)
	print(family_car.compute_price)
```

```python
class Dog():
	def __init__(self,name,age):
		self.name = name
		self.age = age
	def sit_down(self):
		print(self.name.title() + ' is now sitting down!')
	def roll_over(self):
    	print(self.name.title() + ' rolled over!')
    	
#实例化：
a_dog = Dog('tuantuan',0.2)
print(a_dog.name)
a_dog.sit_down
a_dog.roll_over	
```


## 1.3 继承

父类的所有属性，都可以被子类继承。
父类的所有方法，可以被子类选择性地继承：可以覆写（over）父类的同名方法。
子类可以回溯，调用已被覆写的父类方法：super()方法。
call方法。

```python
#先定义一个基类/父类
class people:
	def __init__(self,n,a):
		self.name = n
		self.age = a
	def speak(self):
		print("%s说：我%d岁。"%(self.name,self.age))
	
	#定义了call()方法。调用实例化的类：
	#p = people('Alice',10)
	#p()
	#就可以调用call方法
	def __call__(self):
		print('hello'+self.name)

#再定义派生类/子类
class student(people):
	def __init__(self,n,a,w,g):
		people.__init__(self,n,a) #调用父类的构造函数，从而继承父类的属性
		self.grade = g
	def speak(self): #定义同名的speak函数，将父类的speak方法覆写
		print("%s说:我%d岁了,我在读%d年级"%(self.name,self.age,self.grade))

s = student('ken',10,60,3) #实例化student类
s.speak() #调用这个实例化的student类的方法

#super()就是超，父的意思，返回()里的类的父类，同时保留了属性。
super(student,s).speak() #用student这个子类对象，调用已被覆写的父类的speak方法
```

# 2 TensorFlow2的模块、层、模型

## 2.1 模块

```python
import tensorflow as tf
from datetime import datetime
%load_ext tensorboard

class SimpleModule(tf.Module):
	def __init__(self,name=None):
		super().__init__(name=name)
		self.a_variable = tf.Variable(5.0,name="train_me") #权重可以训练
		self.non_trainable_variable = tf.Variable(5.0,trainable=False,name="do_not_train_me") #偏置不训练
	
	#定义call方法
	def __call__(self,x):
		return self.a_variable*x + self.non_trainable_variable

simple_module = SimpleModule(name='Simple') #实例化
simple_module(tf.constant(5.0)) #调用call方法

#输出各种变量
#输出可训练的变量
print("trainable variables:",simple_module.trainable_variables)
#输出所有的变量
print("all variables:",simple_module.variables)
```

## 2.2 层

搭建一个全连接层

```python
class Dense(tf.Module):
	
	#in_features和out_features分别是这个层的输入参数数目、输出参数数目
	def __init__(self,in_features,out_features,name=None):
		super().__init__(name=name)
		
		#w是权重矩阵，和in_features维的输入张量相乘，得out_features维的输出张量
		#w的维度是in_features * out_features，是一个和输入层全连接的层
		self.w = tf.Variable(tf.random.normal([in_features,out_features]),name='w')
		#b是偏置，是和输出张量维数相等的（一阶）张量
		self.b = tf.Variable(tf.zeros([out_features]),name='b')
	
	def __call__(self,x):
		y = tf.matmul(x,self.w) + self.b
		return tf.nn.relu(y)
```

## 2.3 模型

搭建两层模型

```python
class SequentialModule(tf.Module):
	
	def __init__(self,name=name):
		super().__init__(name=name)
		
		self.dense_1 = Dense(in_features=3,out_features=3)
		self.dense_2 = Dense(in_features=3,out_features=2)
	
	def __call__(self,x):
		x = self.dense_1(x)
		return self.dense_2(x)

my_model = SequentialModule(name='my_model')
#调用my_model的call方法了（注意张量的写法）
print("Model results:",my_model(tf.constant([[2.0,2.0,2.0]])))

#查看my_model这个模型的子模块
print("Submodules:",my_model.submodules)
#查看my_model这个模型的变量
for var in my_model.variables:
	print(var,"\n")
```

# 3 TensorFlow2计算图

计算图（graph）是包含一系列TensorFlow操作（tf.Operation对象）的数据结构。每个操作代表计算单元。

## 3.1 graph的建立：利用tf.function建立图并进行跟踪

**但貌似notebook里不会显示图。**
tf.function可以递归地跟踪它调用的任何python函数。

```python
def function_to_get_faster(x,y,b):
	x = tf.matmul(x,y)
	x = x + b
	return x

#用tf.function()把上述函数赋给“a_function_that_uses_a_graph”
a_function_that_uses_a_graph = tf.function(function_to_get_faster)

#定义几个张量
x1 = tf.constant([[1.0,2.0]])
y1 = tf.constant([[2.0],[3.0]])
b1 = tf.constant(4.0)

#调用函数
a_function_that_uses_a_graph(x1,y1,b1).numpy()
```

另一个例子，利用tensorboard显示图

```python
%load_ext tensorboard
def inner_function(x,y,b):
    x = tf.matmul(x,y)
    x = x + b
    return x

@tf.function
def outer_function(x):
    y = tf.constant([[2.0],[3.0]])
    b = tf.constant(4.0)

    return inner_function(x,y,b)

outer_function(tf.constant([[1.0,2.0]])).numpy()
```

## 3.2 计算图的加速

```python
class SequentialModule(tf.keras.Model):
	def __init__(self,**kwargs):
		super(SequentialModel,self).__init__(**kwargs)
		self.flatten = tf.keras.layers.Flatten(input_shape=(28,28))
		self.dense_1 = tf.keras.layers.Dense(128,activation="relu")
		self.dropout = tf.keras.layers.Dropout(0.2)
		self.dense_2 = tf.keras.layers.Dense(10)
	
	def call(self,x):
		x = self.flatten(x)
		x = self.dense_1(x)
		x = self.dropout(x)
		x = self.dense_2(x)
		return x
input_data = tf.random.uniform([60,28,28])
eager_model = SequentialModel()
graph_model = tf.function(eager_model)

print("Eager time:",timeit.timeit(lambda:eager_model(input_data),number=1000))
print("Graph time:",timeit.timeit(lambda:graph_model(input_data),number=1000))
```

## 3.3 多态性

一个函数，可以多个计算图。

```python
@tf.function
def my_relu(x):
	return tf.maximum(0.,x)
	
print(my_relu(tf.constant(0.5)))
print(my_relu([1,-1]))
print(my_relu(tf.constant([3.,-3.])))
```

# 4 TensorFlow2 训练流程

流程概述：
1 获取训练数据
2 定义模型
3 定义损失函数
4 运行训练数据，从目标值计算损失
5 计算损失的梯度，并使用优化器来调整变量以适应数据
6 结果评估

**实例：**

```python
#获取数据
import matplotlib.pyplot as plt
True_W = 3.0
True_B = 2.0
NUM_EXAMPLE = 1000

x = tf.random.normal(shape=[NUM_EXAMPLE])
noise = tf.random.normal(shape=[NUM_EXAMPLE])
y = x*True_W + True_B  + noise

#定义模型
class MyModel(tf.Module):
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        
        self.w = tf.Variable(5.0)
        self.b = tf.Variable(0.0)
    
    def __call__(self, x):
        return self.w * x + self.b

model = MyModel()

print("Variables: ",model.variables)
assert model(3.0).numpy() == 15.0

#定义损失函数
def loss(target_y, predicted_y):
    return tf.reduce_mean(tf.square(target_y - predicted_y))

plt.scatter(x,y,c='b')
plt.scatter(x,model(x),c='r')
plt.show()
print("current loss is %1.6f"%loss(model(x),y).numpy())

#运行训练数据，从目标值计算损失
#使用梯度下降来训练这个模型
def train(model,x,y,learning_rate):
    with tf.GradientTape() as t:
        current_loss = loss(y,model(x))
    dw,db = t.gradient(current_loss, [model.w, model.b])
    model.w.assign_sub(learning_rate * dw)
    model.b.assign_sub(learning_rate * db)

#计算损失的梯度并用优化器来调整变量
Ws, bs = [], []
epochs = range(10)

def training_loop(model,x,y):
    for epoch in epochs:
        train(model,x,y,learning_rate = 0.1)
        Ws.append(model.w.numpy())
        bs.append(model.b.numpy())
        current_loss = loss(y,model(x))
        
        print("Epoch %2d: W=%1.2f b=%1.2f, loss=%2.5f"%(epoch,Ws[-1],bs[-1],current_loss))

print("Starting: W=%1.2f b=%1.2f, loss=%2.5f" % (model.w, model.b, loss(y, model(x))))

training_loop(model,x,y)

plt.plot(epochs,Ws,"r",epochs,bs,"b")

plt.plot([True_W] * len(epochs),"r--",[True_B] * len(epochs), "b--")

plt.legend(["W","b","True W","True b"])
plt.show()

#结果评估
plt.scatter(x,y,c='b')
plt.scatter(x,model(x),c='r')
print("Current loss is %1.6f" % loss(model(x),y).numpy())
```

也可以用Keras模型实现：

```python
import tensorflow as tf

True_W = 3.0
True_B = 2.0
NUM_EXAMPLE = 1000

x = tf.random.normal(shape=[NUM_EXAMPLE])
noise = tf.random.normal(shape=[NUM_EXAMPLE])
y = x*True_W + True_B  + noise

def loss(target_y, predicted_y):
    return tf.reduce_mean(tf.square(target_y - predicted_y))

def train(model,x,y,learning_rate):
    with tf.GradientTape() as t:
        current_loss = loss(y,model(x))
    dw,db = t.gradient(current_loss, [model.w, model.b])
    model.w.assign_sub(learning_rate * dw)
    model.b.assign_sub(learning_rate * db)

Ws, bs = [], []
epochs = range(20)
def training_loop(model,x,y):
    for epoch in epochs:
        train(model,x,y,learning_rate = 0.1)
        Ws.append(model.w.numpy())
        bs.append(model.b.numpy())
        current_loss = loss(y,model(x))
        
        print("Epoch %2d: W=%1.2f b=%1.2f, loss=%2.5f"%(epoch,Ws[-1],bs[-1],current_loss))
        
class MyModelKeras(tf.keras.Model):
    def __init__(self,**kwargs):
        super().__init__(**kwargs)
        self.w = tf.Variable(5.0)
        self.b = tf.Variable(0.0)
    
    def __call__(self,x,**kwargs):
        return self.w * x + self.b
    
keras_model = MyModelKeras()

training_loop(keras_model, x, y)
keras_model.save_weights("my_checkpoint")
```

# 5 TensorFlow2 数据流水线

具体的练习在tf.data的ipynb文件中有详述。

## 5.1 用tf.data读取数据

从不同的数据格式中读取数据，可进行复杂的变换。
tf.data.Dataset用于表示序列的元素，每个元素是一个基本的训练样本，用一对张量表示图像和对应的标签。

### 5.1.1 用tf.data.Dataset.from_tensor_slices()读取list和numpy

```python
#读取list
tf.data.Dataset.from_tensor_slices([8,3,0,8,2,1])
```

```python
#读取numpy
train, test = tf.keras.datasets.fashion_mnist.load_data()

images, labels = train
images = images/255

dataset = tf.data.Dataset.from_tensor_slices((images, labels))
dataset
```

### 5.1.2 用tf.data.Dataset.from_generator()来产生函数

```python
#产生函数
def count(stop):
    i = 0
    while i<stop:
        yield i
        i += 1

ds_counter = tf.data.Dataset.from_generator(count, args=[25], output_types=tf.int32, output_shapes = (), )
```

### 5.1.3 用tf.data.TFRecordDataset()来读取TFRecord数据

```python
#读取TFRecord数据
fsns_test_file = tf.keras.utils.get_file("fsns.tfrec", "https://storage.googleapis.com/download.tensorflow.org/data/fsns-20160927/testdata/fsns-00000-of-00001")
dataset = tf.data.TFRecordDataset(filenames = [fsns_test_file])
dataset
```

### 5.1.4 用tf.data.TextLineDataset()读取文本数据

```python
#读取文本数据
directory_url = 'https://storage.googleapis.com/download.tensorflow.org/data/illiad/'
file_names = ['cowper.txt', 'derby.txt', 'butler.txt']

file_paths = [
    tf.keras.utils.get_file(file_name, directory_url + file_name)
    for file_name in file_names
]

dataset = tf.data.TextLineDataset(file_paths)

for line in dataset.take(5):
    print(line.numpy())
```

### 5.1.5 用tf.data.experimental.make_csv_dataset()读取表格数据

```python
#获取表格
titanic_file = tf.keras.utils.get_file("train.csv", "https://storage.googleapis.com/tf-datasets/titanic/train.csv")
#用pandas可以读
df = pd.read_csv(titanic_file, index_col=None)
df.head()
#用tf.data也可以读
titanic_batches = tf.data.experimental.make_csv_dataset(
    titanic_file, batch_size=4,
    label_name="survived")
for feature_batch, label_batch in titanic_batches.take(1):
    print("'survived': {}".format(label_batch))
    print("features:")
    for key, value in feature_batch.items():
        print("  {!r:20s}: {}".format(key, value))
```

### 5.1.6 用dataset.shuffle(buffer_size=2)来打乱数据

```python
dataset = dataset.shuffle(buffer_size=2)#缓存区只有2，打乱效果差
for elem in dataset:
    print(elem.numpy())
```

### 5.1.7 用dataset.map(预处理函数)数据预处理

```python
flowers_root = tf.keras.utils.get_file('flower_photos','https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz', untar=True)
flowers_root = pathlib.Path(flowers_root)

list_ds = tf.data.Dataset.list_files(str(flowers_root/'*/*'))

# Reads an image from a file, decodes it into a dense tensor, and resizes it to a fixed shape.
#此处定义预处理函数
def parse_image(filename):
    parts = tf.strings.split(filename, os.sep)
    label = parts[-2]

    image = tf.io.read_file(filename)
    image = tf.image.decode_jpeg(image)
    image = tf.image.convert_image_dtype(image, tf.float32)
    image = tf.image.resize(image, [128, 128])
    return image, label
    
file_path = next(iter(list_ds))
image, label = parse_image(file_path)

def show(image, label):
    plt.figure()
    plt.imshow(image)
    plt.title(label.numpy().decode('utf-8'))
    plt.axis('off')

show(image, label)

#显示出花朵的图片
#调用预处理函数
images_ds = list_ds.map(parse_image)

for image, label in images_ds.take(2):
    show(image, label)
    
#继续显示花朵的图片

import scipy.ndimage as ndimage

#定义了对图片随机旋转的函数
def random_rotate_image(image):
    image = ndimage.rotate(image, np.random.uniform(-30, 30), reshape=False)
    return image
    
image, label = next(iter(images_ds))
image = random_rotate_image(image)
show(image, label)

#显示出旋转后的图片
```

### 5.1.8对类别不平衡数据的处理

```python
#获取数据文件
zip_path = tf.keras.utils.get_file(origin='https://storage.googleapis.com/download.tensorflow.org/data/creditcard.zip', fname='creditcard.zip', extract=True)

csv_path = zip_path.replace('.zip', '.csv')

#读取表格数据
creditcard_ds = tf.data.experimental.make_csv_dataset(
    csv_path, batch_size=1024, label_name="Class",
    # Set the column types: 30 floats and an int.
    column_defaults=[float()]*30+[int()])

def count(counts, batch):
    features, labels = batch
    class_1 = labels == 1
    class_1 = tf.cast(class_1, tf.int32)

    class_0 = labels == 0
    class_0 = tf.cast(class_0, tf.int32)

    counts['class_0'] += tf.reduce_sum(class_0)
    counts['class_1'] += tf.reduce_sum(class_1)

    return counts

counts = creditcard_ds.take(10).reduce(
    initial_state={'class_0': 0, 'class_1': 0},
    reduce_func = count)

counts = np.array([counts['class_0'].numpy(),
                   counts['class_1'].numpy()]).astype(np.float32)

fractions = counts/counts.sum()
print(fractions)

negative_ds = (
  creditcard_ds
    .unbatch()
    .filter(lambda features, label: label==0)
    .repeat())
positive_ds = (
  creditcard_ds
    .unbatch()
    .filter(lambda features, label: label==1)
    .repeat())

for features, label in positive_ds.batch(10).take(1):
    print(label.numpy())
```

**方法一，tf.data.experimental.sample_from_datasets**

```python
for features, label in positive_ds.batch(10).take(1):
    print(label.numpy())

for features, labels in balanced_ds.take(10):
    print(labels.numpy())
```

**方法二，tf.data.experimental.rejection_resample**

```python
def class_func(features, label):
    return label

resampler = tf.data.experimental.rejection_resample(
    class_func, target_dist=[0.5, 0.5], initial_dist=fractions)

resample_ds = creditcard_ds.unbatch().apply(resampler).batch(10)

balanced_ds = resample_ds.map(lambda extra_label, features_and_label: features_and_label)

for features, labels in balanced_ds.take(10):
    print(labels.numpy())
```

## 5.2 用tf.data加载图片示例

利用高级API读取图片

```python

flowers = tf.keras.utils.get_file('flower_photos','https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz', untar=True)

img_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255, rotation_range=20)

print(flowers)

images, labels = next(img_gen.flow_from_directory(flowers))
```