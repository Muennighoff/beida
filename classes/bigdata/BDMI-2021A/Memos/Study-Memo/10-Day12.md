# Week 12 Summary

# 课程大纲
```
循环网络（RNN）
	原理
	基本结构
	变种（长短时记忆网络/门控循环单元网络）
	应用
	扩展
```

##  Keras2 循环网络的应用
```
word embeddings 单词嵌入
	把语言转换成向量的形式
	之后进行 文本分类 和 文本生成

音乐生成
机器翻译的注意力机制
图像注解
```

## 卷积网络/循环网络
```
循环网络是多重网络结构

多个 单个神经元 组合起来就可以变成多层人工神经网络

本节课所用的网络结构是 反馈网络（输出作为输入）

卷积网络：基于卷积运算

循环网络 RNN recurrent neural network
特点：
	在时间维度上进行权重共享
	会用到循环的反馈链接：
		隐藏层的当前状态会反馈到下一个时刻的状态

基本循环网络 vanilla RNN
	权重网络
	每一层之间都是全连接
	
如何将之前的神经网络演示转换成RNN？
	先将模型左旋90度
	之后出现三个同样的（t-1、t、t+1）
	
RNN示例：
	输入 hello
	对字母进行向量化的编码

BPTT：
	一前一后反复计算
	
循环网络训练存在的问题：
	梯度太大或太小

RNN扩展： 双向RNN
	一个时间上从序列起点开始移动，另一个从末尾开始移动
用途：
	手写识别
	语音识别
	自然语言处理

长短时记忆网络 LSTM
	三个门:输入门、输出门、遗忘门（是否存储）

GRU 门控循环单元全程
	计算量较少
	比标准LSTM简单
	合并了输入门和遗忘门
	合并了记忆cell状态和隐藏状态
```

## 循环网络应用
```
机器翻译
识别
标签
```

## RNN
```
model = keras.Sequantial()

model.add(tf.keras.layers.SimpleRNNCell())
```