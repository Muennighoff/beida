## 学习小结-1117-day10
---

#### 1. Python面向对象编程

- 类

  - 类（class）：某一类对象的抽象定义

    对象（object）：类的一个实例

    属性（attribute）：类（类属性）或者类实例（实例属性）的特征

    方法（method）：类可以实现的一个操作

    参数（parameters）：影响方法行为的输入

    实例化（instance）：根据某个抽象类创建具体对象的过程

- 继承

  - `class Derived_class(Base_class):`

  - `super()`：子类对象调用父类已经被覆盖的方法

    `super(derived_class, class_name).method_name()`

  - `def __call__(self)`：相当于c++运算符重载`operator()`，可以使用`class_name()`调用该方法


#### 2. TensorFlow2

- 模块、层和模型
     - 模块（定义、保存、恢复）

       对张量进行计算的函数（前向计算）

       变量在训练过程中被更新

       ```python
       #实现a*x+b
       import tensorflow as tf
       from datetime import datetime
       
       %load_ext tensorboard
       class SimpleModule(tf.Module):
         def __init__(self, name=None):
           super().__init__(name=name)
           self.a_variable = tf.Variable(5.0, name="train_me")
           self.non_trainable_variable = tf.Variable(5.0, trainable=False, name="do_not_train_me")
         def __call__(self, x):
           return self.a_variable * x + self.non_trainable_variable
       # All trainable variables
       print("trainable variables:", simple_module.trainable_variables)
       # Every variable
       print("all variables:", simple_module.variables)
       ```

     - 在TensorFlow中定义模型（Model）和层（Layers）

       层：可重用的带参数的结构

       ```python
       #全连接层w*x+b
       class Dense(tf.Module):
         def __init__(self, in_features, out_features, name=None):
           super().__init__(name=name)
           self.w = tf.Variable(
             tf.random.normal([in_features, out_features]), name='w')
           self.b = tf.Variable(tf.zeros([out_features]), name='b')
         def __call__(self, x):
           y = tf.matmul(x, self.w) + self.b
           return tf.nn.relu(y)
       #此模型将创建并应用了两个层
       class SequentialModule(tf.Module):
         def __init__(self, name=None):
           super().__init__(name=name)
           self.dense_1 = Dense(in_features=3, out_features=3)
           self.dense_2 = Dense(in_features=3, out_features=1)
       
         def __call__(self, x):
           x = self.dense_1(x)
           return self.dense_2(x)
       
       x=tf.reshape(tf.constant([0.0288,-0.3256,0.5925]),[1,3])
       mm = SequentialModule()
       print(mm(x))
       ```

       所有模型和层都是`tf.Module`的派生类

     - tensorboard：

       对TensorFlow模型和张量进行可视化的工具

- 计算图
     - Graph是包含一系列tensorflow操作（tf.Operation对象）的数据结构，这些操作代表计算单元

       Graph包含（tf.Tensor对象）Tensor（张量），代表操作之间流动的数据单位

       他们是在tf.Graph上下文中定义的

     - 优势

       计算图拥有很大的灵活性

       计算图执行效率高

       计算图容易优化

     - Graph的建立

       利用`tf.function`建立图并进行追踪，其功能化的函数也是Python可调用的函数

- 训练循环（流程）
     - 获取训练数据
     - 定义模型
     - 定义损失函数
     - 运行训练数据，从目标值计算损失
     - 计算损失的梯度，并使用优化器来调整变量以适应数据
     - 结果评估

- 数据流水线`tf.data`

  - 用途

    TensorFlow数据结构`tf.data API`借口用于处理大量数据，包括从不同的数据格式中读取数据和进行复杂变换

    `tf.data.Dataset`用于表示序列的元素，每个元素是一个基本的训练样本，用一对张量表示图像和对应的标签

  - 读取数据

    从`list`中读取

    ```python
    dataset = tf.data.Dataset.from_tensor_slices([8, 3, 0, 8, 2, 1])
    dataset
    ```

    读取numpy数据

    ```python
    train, test = tf.keras.datasets.fashion_mnist.load_data()
    images, labels = train
    images = images/255
    
    dataset = tf.data.Dataset.from_tensor_slices((images, labels))
    dataset
    ```

    利用数据生成函数

    ```python
    def count(stop):
      i = 0
      while i<stop:
        yield i
        i += 1
        
    ds_counter = tf.data.Dataset.from_generator(count, args=[25], output_types=tf.int32, output_shapes = (), )
    for count_batch in ds_counter.repeat().batch(10).take(10):
      print(count_batch.numpy())
    ```

    

