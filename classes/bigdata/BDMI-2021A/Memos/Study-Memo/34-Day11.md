# 第十一周

## 1 自动微分

### 1.求导运算

**数值微分：** 利用导数定义取小量运算。误差、计算效率问题

**符号微分：** 记录所用函数，算出导函数后代入计算导数。求导函数复杂度高、需要保存大量中间变量

### 2.自动微分

**前向模式：** 基于计算图反向计算输出对**某个**输入的微分。

**反向模式：** 计算输出对所有输入的微分值

### 3.反向传播算法与反向计算图

**反向传播算法：** 先按前向传播方式计算，并缓存每个节点的输出值，然后再按反向传播遍历图的方式，计算损失函数相对于每一个参数的偏导数。

**反向计算图：** 通过图的方式避免缓存中间数值带来的存储空间

**反向计算图构建：** 从输出结果开始，查找依赖节点->计算梯度->插入->递归。

**自动微分：** tensorflow2构建梯度带，梯度带自动构建了反向计算图。

## 2 卷积网络

**基本结构：** 前馈网络的典型结构，层与层之间拒不连接。

**卷积运算：** 对输入的多维数组应用卷积核（多维数组）进行运算的过程。

**下采样层：** 利用池化方法，缩小输出张量的大小。

**归一化层：** 有时在卷积运算之后添加。eg:LCN层起到减去平均值、除以标准差的作用

**卷积神经网络：** 卷积层+非线性激活单元+池化层+随机丢弃。具有计算快、参数少、可并行化的特点。

## 3 Keras

Keras:快速搭建深度神经网络的高级API。

### 1.基本结构

**层：** `tf.keras.layers` 包括多种封装好的层 `Dense` `Activation` `Flatten` `Dropout` `Reshape` `Masking`等和常用的卷积层、池化层等。

**激活函数：** `softmax` `elu` `relu` `tanh`等。

**优化器：** `Optimizer` `SGD` `Adam` `Nadam`等。其中，`RMSprop` `Adagrad` `Adam`可以自适应调整学习率，`Nadam`可以基于所有梯度信息更新参数、进一步提高收敛速度。

### 2.使用流程

**定义网络：**

    from keras.models import Sequetial
    from keras.layers import Dense, Activation

    model = Sequential([
        Dense(32, input_dim=784),
        Activation('relu'),
        Dense(10),
        Activation('softmax'),
    ])

**编译网络：**

    model.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics=['accuracy'])

**网络训练：**

    import numpy as np
    data = np.random.random((1000, 784))
    labels = np.random.randint(2, size=(1000,1))
    model.fit(data, labels, nb_epoch=10,batch_size=32)

**评估网络：**

    model.evaluate(self,x,y,batch_size=32,verbose=1,sample_weight=None)

**数据预测：** 

    model.predict(self,x,batch_size=32,verbose=0)

**保存/载入：**

    model.save()
    tf.keras.models.load_model()

## 4 顺序模型

适用于普通堆栈的图层，每个图层只有一个输入张量和输出张量

    model = keras.Sequential([
        layers.Dense(2, activation='relu', name='l1')
        layers.Dense(2, activation='relu', name='l2')
    ])      #两个Dense层组成的顺序模型

不适用于多个输入或多个输出的情况

特别的，Sequential可以通过add(),pop()来进行层的添加和删除

    model.add(layers.Dense(2, activation='relu', name='l3'))
    model.pop()

在创建模型时，需要预先指定输入形状

    model.add(keras.Inout(shape=(4,)))

顺序模型还可以通过`feature_extreactor()`函数来进行模型功能功能提取。

还可以通过堆叠预训练的模型和新初始化的分类层进行迁移学习。

## 5 模型与层

**Layer:** 权重与部分计算的组合。通过add_weight()方法可以增加权重，权重可以设置为可训练、不可训练，不可训练权重不会被反向传播考虑。

    a_layer.add_weight(shape=(1,2), initializer='random_normal',trainable='True')

通过``build`方法可以延迟创建权重，达到依据输入创建权重的目的

**Model:** 具有与Layer相同的API，但是会公开内置训练、评估和预测循环，可以通过model.layers公开内部层，可以公开保存和序列化API。 

**保存与加载：** 模型可以保存在单个文件中，包括架构、权重、编译信息、优化器。保存架构可以通过`get_config()` `from_config()`来进行，可以通过`tf.keras.layers.Layer.get_weights()` `tf.keras.layers.Layer.set_weights()`来复制权重，通过`model.save_weights()` `model.load_weights()`保存权重，=。

## 6 一个实例

[文件](flower.ipynb)