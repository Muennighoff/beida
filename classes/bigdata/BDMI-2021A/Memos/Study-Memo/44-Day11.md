# 第十一周课程小结

## 自动微分
* 符号微分：复杂度指数级增加，且需要保存大量的中间数据，容易出错

* 数值微分

$$
f(x_1,x_2)=ln(x_1)+x_1x_2-sin(x_2)
$$
### Forward Mode
前向计算：计算输出对某个输入的微分
本质上一次前向过程，计算了雅可比向量乘积，获得雅可比矩阵的一列
### Backward Mode
反向计算：计算输出对所有输入的微分值
一次反向过程计算了转置后的雅可比矩阵的一列 

## 卷积网络Convolution Network
卷积网络属于前馈网络典型结构，是局部连接
* 卷积核：一个多为数组
输出长度计算：填充式P、输入的长度W、卷积核的大小F、移动的步长S
L=(W-F+2P)/S +1 

## Keras
```python
import tensorflow as tf
from tensorflow import keras
```
### Keras核心概念
* 模型：顺序模型（sequentia Model）
* 层：tf.keras.layers 
* 激活函数：tf.keras.activations
* 优化器

### Keras使用流程

1. 定义网络
2. 编译网络
3. 训练网络
4. 评估网络
5. 数据预测
6. 保存/载入网络

### Keras 顺序模型
不适用于顺序模型的情况：
* 模型有多个输入或者多个输出
* 任何层都有多个输入或多个输出
* 需要做图层共享
* 需要非线性拓扑

**顺序模型的创建**
方法一：通过将层列表传递给顺序构造函数来创建顺序模型
方法二：通过add（）以增量方式创建模型，以pop（）删除层

创建顺序模型需要预先指定输入形状

## 迁移学习
迁移学习包括冻结模型中得底层，而只训练顶层
* 方案一：迭代模型层然后设置可训练层=除最后一层外，每层均为假
* 方案二：使用顺序模型来堆叠预先训练的模型和一些新初始化的分类层

## Keras模型的保存和加载
保存和加载整个模型：
* tf.keras.models.save_model()
* tf.keras.models.load_model()

仅保存网络架构：
* get_config()
* from_config()

仅保存和加载模型的权重：
* tf.keras.layers.Layer.get_weights()
* tf.keras.layers.Layer.set_weights()