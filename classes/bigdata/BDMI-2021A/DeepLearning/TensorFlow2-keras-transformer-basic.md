


|时间段 |    内容    |   讲课 / 实践     |    分工  |  备注       |
| :---  |   :---------------:  |  :----------:   |    :----:    | :--- |
|   8   | [TensorFlow2-语言理解Transformer]()   | 讲课 |  ZZF   |  https://tensorflow.google.cn/tutorials/text/transformer   |
|   9   | [TensorFlow2-BERT模型]()   | 讲课 |  ZZF   |  https://tensorflow.google.cn/text/tutorials/fine_tune_bert   |


Transformer

[Attention Is All You Need](https://arxiv.org/abs/1706.03762)

BERT, Bidirectional Encoder Representations from Transformers

[BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)